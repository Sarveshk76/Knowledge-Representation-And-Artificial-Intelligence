{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KR_AI_Pytorch_NN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgwk-ogYTIp6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining i/p size, hidden layer, o/p size, batch size\n",
        "n_in, n_h, n_out, batch_size = 10,5,1,10"
      ],
      "metadata": {
        "id": "tcYO_ZR2TS1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create dummy i/p and target tensors\n",
        "x = torch.randn(batch_size,n_in)\n",
        "y = torch.tensor([[1.0],[0.0],[0.0],[1.0],[1.0],[1.0],[0.0],[0.0],[1.0],[1.0]])"
      ],
      "metadata": {
        "id": "OibY_r8ETvPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Sequential model\n",
        "model = nn.Sequential(nn.Linear(n_in,n_h), nn.ReLU(), nn.Linear(n_h,n_out), nn.Sigmoid())"
      ],
      "metadata": {
        "id": "rw23w4vcUcbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Construct the loss function with the help of Gradient Descent optimizer\n",
        "criterion = torch.nn.MSELoss()\n",
        "#Stochatic Gradient Descent\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n"
      ],
      "metadata": {
        "id": "sM3d02wzU7Ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Implement the gradient descent model with the iterating loop\n",
        "for epoch in range(1000):\n",
        "  #Forward pass\n",
        "  y_pred = model(x)\n",
        "  #Compute and print loss\n",
        "  loss = criterion(y_pred,y)\n",
        "  print('epoch: ',epoch,'loss: ',loss)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxF8ZzX-VY4p",
        "outputId": "3dad573e-a0c7-4a25-ea1d-1d2be01f1a0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  0 loss:  tensor(0.2706, grad_fn=<MseLossBackward0>)\n",
            "epoch:  1 loss:  tensor(0.2705, grad_fn=<MseLossBackward0>)\n",
            "epoch:  2 loss:  tensor(0.2703, grad_fn=<MseLossBackward0>)\n",
            "epoch:  3 loss:  tensor(0.2702, grad_fn=<MseLossBackward0>)\n",
            "epoch:  4 loss:  tensor(0.2700, grad_fn=<MseLossBackward0>)\n",
            "epoch:  5 loss:  tensor(0.2699, grad_fn=<MseLossBackward0>)\n",
            "epoch:  6 loss:  tensor(0.2698, grad_fn=<MseLossBackward0>)\n",
            "epoch:  7 loss:  tensor(0.2696, grad_fn=<MseLossBackward0>)\n",
            "epoch:  8 loss:  tensor(0.2695, grad_fn=<MseLossBackward0>)\n",
            "epoch:  9 loss:  tensor(0.2694, grad_fn=<MseLossBackward0>)\n",
            "epoch:  10 loss:  tensor(0.2692, grad_fn=<MseLossBackward0>)\n",
            "epoch:  11 loss:  tensor(0.2691, grad_fn=<MseLossBackward0>)\n",
            "epoch:  12 loss:  tensor(0.2689, grad_fn=<MseLossBackward0>)\n",
            "epoch:  13 loss:  tensor(0.2688, grad_fn=<MseLossBackward0>)\n",
            "epoch:  14 loss:  tensor(0.2687, grad_fn=<MseLossBackward0>)\n",
            "epoch:  15 loss:  tensor(0.2685, grad_fn=<MseLossBackward0>)\n",
            "epoch:  16 loss:  tensor(0.2684, grad_fn=<MseLossBackward0>)\n",
            "epoch:  17 loss:  tensor(0.2683, grad_fn=<MseLossBackward0>)\n",
            "epoch:  18 loss:  tensor(0.2681, grad_fn=<MseLossBackward0>)\n",
            "epoch:  19 loss:  tensor(0.2680, grad_fn=<MseLossBackward0>)\n",
            "epoch:  20 loss:  tensor(0.2679, grad_fn=<MseLossBackward0>)\n",
            "epoch:  21 loss:  tensor(0.2677, grad_fn=<MseLossBackward0>)\n",
            "epoch:  22 loss:  tensor(0.2676, grad_fn=<MseLossBackward0>)\n",
            "epoch:  23 loss:  tensor(0.2675, grad_fn=<MseLossBackward0>)\n",
            "epoch:  24 loss:  tensor(0.2674, grad_fn=<MseLossBackward0>)\n",
            "epoch:  25 loss:  tensor(0.2672, grad_fn=<MseLossBackward0>)\n",
            "epoch:  26 loss:  tensor(0.2671, grad_fn=<MseLossBackward0>)\n",
            "epoch:  27 loss:  tensor(0.2670, grad_fn=<MseLossBackward0>)\n",
            "epoch:  28 loss:  tensor(0.2668, grad_fn=<MseLossBackward0>)\n",
            "epoch:  29 loss:  tensor(0.2667, grad_fn=<MseLossBackward0>)\n",
            "epoch:  30 loss:  tensor(0.2666, grad_fn=<MseLossBackward0>)\n",
            "epoch:  31 loss:  tensor(0.2665, grad_fn=<MseLossBackward0>)\n",
            "epoch:  32 loss:  tensor(0.2663, grad_fn=<MseLossBackward0>)\n",
            "epoch:  33 loss:  tensor(0.2662, grad_fn=<MseLossBackward0>)\n",
            "epoch:  34 loss:  tensor(0.2661, grad_fn=<MseLossBackward0>)\n",
            "epoch:  35 loss:  tensor(0.2660, grad_fn=<MseLossBackward0>)\n",
            "epoch:  36 loss:  tensor(0.2658, grad_fn=<MseLossBackward0>)\n",
            "epoch:  37 loss:  tensor(0.2657, grad_fn=<MseLossBackward0>)\n",
            "epoch:  38 loss:  tensor(0.2656, grad_fn=<MseLossBackward0>)\n",
            "epoch:  39 loss:  tensor(0.2655, grad_fn=<MseLossBackward0>)\n",
            "epoch:  40 loss:  tensor(0.2653, grad_fn=<MseLossBackward0>)\n",
            "epoch:  41 loss:  tensor(0.2652, grad_fn=<MseLossBackward0>)\n",
            "epoch:  42 loss:  tensor(0.2651, grad_fn=<MseLossBackward0>)\n",
            "epoch:  43 loss:  tensor(0.2650, grad_fn=<MseLossBackward0>)\n",
            "epoch:  44 loss:  tensor(0.2649, grad_fn=<MseLossBackward0>)\n",
            "epoch:  45 loss:  tensor(0.2647, grad_fn=<MseLossBackward0>)\n",
            "epoch:  46 loss:  tensor(0.2646, grad_fn=<MseLossBackward0>)\n",
            "epoch:  47 loss:  tensor(0.2645, grad_fn=<MseLossBackward0>)\n",
            "epoch:  48 loss:  tensor(0.2644, grad_fn=<MseLossBackward0>)\n",
            "epoch:  49 loss:  tensor(0.2643, grad_fn=<MseLossBackward0>)\n",
            "epoch:  50 loss:  tensor(0.2642, grad_fn=<MseLossBackward0>)\n",
            "epoch:  51 loss:  tensor(0.2640, grad_fn=<MseLossBackward0>)\n",
            "epoch:  52 loss:  tensor(0.2639, grad_fn=<MseLossBackward0>)\n",
            "epoch:  53 loss:  tensor(0.2638, grad_fn=<MseLossBackward0>)\n",
            "epoch:  54 loss:  tensor(0.2637, grad_fn=<MseLossBackward0>)\n",
            "epoch:  55 loss:  tensor(0.2636, grad_fn=<MseLossBackward0>)\n",
            "epoch:  56 loss:  tensor(0.2635, grad_fn=<MseLossBackward0>)\n",
            "epoch:  57 loss:  tensor(0.2633, grad_fn=<MseLossBackward0>)\n",
            "epoch:  58 loss:  tensor(0.2632, grad_fn=<MseLossBackward0>)\n",
            "epoch:  59 loss:  tensor(0.2631, grad_fn=<MseLossBackward0>)\n",
            "epoch:  60 loss:  tensor(0.2630, grad_fn=<MseLossBackward0>)\n",
            "epoch:  61 loss:  tensor(0.2629, grad_fn=<MseLossBackward0>)\n",
            "epoch:  62 loss:  tensor(0.2628, grad_fn=<MseLossBackward0>)\n",
            "epoch:  63 loss:  tensor(0.2627, grad_fn=<MseLossBackward0>)\n",
            "epoch:  64 loss:  tensor(0.2626, grad_fn=<MseLossBackward0>)\n",
            "epoch:  65 loss:  tensor(0.2625, grad_fn=<MseLossBackward0>)\n",
            "epoch:  66 loss:  tensor(0.2623, grad_fn=<MseLossBackward0>)\n",
            "epoch:  67 loss:  tensor(0.2622, grad_fn=<MseLossBackward0>)\n",
            "epoch:  68 loss:  tensor(0.2621, grad_fn=<MseLossBackward0>)\n",
            "epoch:  69 loss:  tensor(0.2620, grad_fn=<MseLossBackward0>)\n",
            "epoch:  70 loss:  tensor(0.2619, grad_fn=<MseLossBackward0>)\n",
            "epoch:  71 loss:  tensor(0.2618, grad_fn=<MseLossBackward0>)\n",
            "epoch:  72 loss:  tensor(0.2617, grad_fn=<MseLossBackward0>)\n",
            "epoch:  73 loss:  tensor(0.2616, grad_fn=<MseLossBackward0>)\n",
            "epoch:  74 loss:  tensor(0.2615, grad_fn=<MseLossBackward0>)\n",
            "epoch:  75 loss:  tensor(0.2614, grad_fn=<MseLossBackward0>)\n",
            "epoch:  76 loss:  tensor(0.2613, grad_fn=<MseLossBackward0>)\n",
            "epoch:  77 loss:  tensor(0.2612, grad_fn=<MseLossBackward0>)\n",
            "epoch:  78 loss:  tensor(0.2611, grad_fn=<MseLossBackward0>)\n",
            "epoch:  79 loss:  tensor(0.2610, grad_fn=<MseLossBackward0>)\n",
            "epoch:  80 loss:  tensor(0.2608, grad_fn=<MseLossBackward0>)\n",
            "epoch:  81 loss:  tensor(0.2607, grad_fn=<MseLossBackward0>)\n",
            "epoch:  82 loss:  tensor(0.2606, grad_fn=<MseLossBackward0>)\n",
            "epoch:  83 loss:  tensor(0.2605, grad_fn=<MseLossBackward0>)\n",
            "epoch:  84 loss:  tensor(0.2604, grad_fn=<MseLossBackward0>)\n",
            "epoch:  85 loss:  tensor(0.2603, grad_fn=<MseLossBackward0>)\n",
            "epoch:  86 loss:  tensor(0.2602, grad_fn=<MseLossBackward0>)\n",
            "epoch:  87 loss:  tensor(0.2601, grad_fn=<MseLossBackward0>)\n",
            "epoch:  88 loss:  tensor(0.2600, grad_fn=<MseLossBackward0>)\n",
            "epoch:  89 loss:  tensor(0.2599, grad_fn=<MseLossBackward0>)\n",
            "epoch:  90 loss:  tensor(0.2598, grad_fn=<MseLossBackward0>)\n",
            "epoch:  91 loss:  tensor(0.2597, grad_fn=<MseLossBackward0>)\n",
            "epoch:  92 loss:  tensor(0.2596, grad_fn=<MseLossBackward0>)\n",
            "epoch:  93 loss:  tensor(0.2595, grad_fn=<MseLossBackward0>)\n",
            "epoch:  94 loss:  tensor(0.2594, grad_fn=<MseLossBackward0>)\n",
            "epoch:  95 loss:  tensor(0.2593, grad_fn=<MseLossBackward0>)\n",
            "epoch:  96 loss:  tensor(0.2592, grad_fn=<MseLossBackward0>)\n",
            "epoch:  97 loss:  tensor(0.2591, grad_fn=<MseLossBackward0>)\n",
            "epoch:  98 loss:  tensor(0.2590, grad_fn=<MseLossBackward0>)\n",
            "epoch:  99 loss:  tensor(0.2589, grad_fn=<MseLossBackward0>)\n",
            "epoch:  100 loss:  tensor(0.2588, grad_fn=<MseLossBackward0>)\n",
            "epoch:  101 loss:  tensor(0.2587, grad_fn=<MseLossBackward0>)\n",
            "epoch:  102 loss:  tensor(0.2586, grad_fn=<MseLossBackward0>)\n",
            "epoch:  103 loss:  tensor(0.2586, grad_fn=<MseLossBackward0>)\n",
            "epoch:  104 loss:  tensor(0.2585, grad_fn=<MseLossBackward0>)\n",
            "epoch:  105 loss:  tensor(0.2584, grad_fn=<MseLossBackward0>)\n",
            "epoch:  106 loss:  tensor(0.2583, grad_fn=<MseLossBackward0>)\n",
            "epoch:  107 loss:  tensor(0.2582, grad_fn=<MseLossBackward0>)\n",
            "epoch:  108 loss:  tensor(0.2581, grad_fn=<MseLossBackward0>)\n",
            "epoch:  109 loss:  tensor(0.2580, grad_fn=<MseLossBackward0>)\n",
            "epoch:  110 loss:  tensor(0.2579, grad_fn=<MseLossBackward0>)\n",
            "epoch:  111 loss:  tensor(0.2578, grad_fn=<MseLossBackward0>)\n",
            "epoch:  112 loss:  tensor(0.2577, grad_fn=<MseLossBackward0>)\n",
            "epoch:  113 loss:  tensor(0.2576, grad_fn=<MseLossBackward0>)\n",
            "epoch:  114 loss:  tensor(0.2575, grad_fn=<MseLossBackward0>)\n",
            "epoch:  115 loss:  tensor(0.2574, grad_fn=<MseLossBackward0>)\n",
            "epoch:  116 loss:  tensor(0.2573, grad_fn=<MseLossBackward0>)\n",
            "epoch:  117 loss:  tensor(0.2572, grad_fn=<MseLossBackward0>)\n",
            "epoch:  118 loss:  tensor(0.2572, grad_fn=<MseLossBackward0>)\n",
            "epoch:  119 loss:  tensor(0.2571, grad_fn=<MseLossBackward0>)\n",
            "epoch:  120 loss:  tensor(0.2570, grad_fn=<MseLossBackward0>)\n",
            "epoch:  121 loss:  tensor(0.2569, grad_fn=<MseLossBackward0>)\n",
            "epoch:  122 loss:  tensor(0.2568, grad_fn=<MseLossBackward0>)\n",
            "epoch:  123 loss:  tensor(0.2567, grad_fn=<MseLossBackward0>)\n",
            "epoch:  124 loss:  tensor(0.2566, grad_fn=<MseLossBackward0>)\n",
            "epoch:  125 loss:  tensor(0.2565, grad_fn=<MseLossBackward0>)\n",
            "epoch:  126 loss:  tensor(0.2564, grad_fn=<MseLossBackward0>)\n",
            "epoch:  127 loss:  tensor(0.2563, grad_fn=<MseLossBackward0>)\n",
            "epoch:  128 loss:  tensor(0.2563, grad_fn=<MseLossBackward0>)\n",
            "epoch:  129 loss:  tensor(0.2562, grad_fn=<MseLossBackward0>)\n",
            "epoch:  130 loss:  tensor(0.2561, grad_fn=<MseLossBackward0>)\n",
            "epoch:  131 loss:  tensor(0.2560, grad_fn=<MseLossBackward0>)\n",
            "epoch:  132 loss:  tensor(0.2559, grad_fn=<MseLossBackward0>)\n",
            "epoch:  133 loss:  tensor(0.2558, grad_fn=<MseLossBackward0>)\n",
            "epoch:  134 loss:  tensor(0.2557, grad_fn=<MseLossBackward0>)\n",
            "epoch:  135 loss:  tensor(0.2557, grad_fn=<MseLossBackward0>)\n",
            "epoch:  136 loss:  tensor(0.2556, grad_fn=<MseLossBackward0>)\n",
            "epoch:  137 loss:  tensor(0.2555, grad_fn=<MseLossBackward0>)\n",
            "epoch:  138 loss:  tensor(0.2554, grad_fn=<MseLossBackward0>)\n",
            "epoch:  139 loss:  tensor(0.2553, grad_fn=<MseLossBackward0>)\n",
            "epoch:  140 loss:  tensor(0.2552, grad_fn=<MseLossBackward0>)\n",
            "epoch:  141 loss:  tensor(0.2551, grad_fn=<MseLossBackward0>)\n",
            "epoch:  142 loss:  tensor(0.2551, grad_fn=<MseLossBackward0>)\n",
            "epoch:  143 loss:  tensor(0.2550, grad_fn=<MseLossBackward0>)\n",
            "epoch:  144 loss:  tensor(0.2549, grad_fn=<MseLossBackward0>)\n",
            "epoch:  145 loss:  tensor(0.2548, grad_fn=<MseLossBackward0>)\n",
            "epoch:  146 loss:  tensor(0.2547, grad_fn=<MseLossBackward0>)\n",
            "epoch:  147 loss:  tensor(0.2546, grad_fn=<MseLossBackward0>)\n",
            "epoch:  148 loss:  tensor(0.2546, grad_fn=<MseLossBackward0>)\n",
            "epoch:  149 loss:  tensor(0.2545, grad_fn=<MseLossBackward0>)\n",
            "epoch:  150 loss:  tensor(0.2544, grad_fn=<MseLossBackward0>)\n",
            "epoch:  151 loss:  tensor(0.2543, grad_fn=<MseLossBackward0>)\n",
            "epoch:  152 loss:  tensor(0.2542, grad_fn=<MseLossBackward0>)\n",
            "epoch:  153 loss:  tensor(0.2542, grad_fn=<MseLossBackward0>)\n",
            "epoch:  154 loss:  tensor(0.2541, grad_fn=<MseLossBackward0>)\n",
            "epoch:  155 loss:  tensor(0.2540, grad_fn=<MseLossBackward0>)\n",
            "epoch:  156 loss:  tensor(0.2539, grad_fn=<MseLossBackward0>)\n",
            "epoch:  157 loss:  tensor(0.2538, grad_fn=<MseLossBackward0>)\n",
            "epoch:  158 loss:  tensor(0.2538, grad_fn=<MseLossBackward0>)\n",
            "epoch:  159 loss:  tensor(0.2537, grad_fn=<MseLossBackward0>)\n",
            "epoch:  160 loss:  tensor(0.2536, grad_fn=<MseLossBackward0>)\n",
            "epoch:  161 loss:  tensor(0.2535, grad_fn=<MseLossBackward0>)\n",
            "epoch:  162 loss:  tensor(0.2534, grad_fn=<MseLossBackward0>)\n",
            "epoch:  163 loss:  tensor(0.2534, grad_fn=<MseLossBackward0>)\n",
            "epoch:  164 loss:  tensor(0.2533, grad_fn=<MseLossBackward0>)\n",
            "epoch:  165 loss:  tensor(0.2532, grad_fn=<MseLossBackward0>)\n",
            "epoch:  166 loss:  tensor(0.2531, grad_fn=<MseLossBackward0>)\n",
            "epoch:  167 loss:  tensor(0.2530, grad_fn=<MseLossBackward0>)\n",
            "epoch:  168 loss:  tensor(0.2530, grad_fn=<MseLossBackward0>)\n",
            "epoch:  169 loss:  tensor(0.2529, grad_fn=<MseLossBackward0>)\n",
            "epoch:  170 loss:  tensor(0.2528, grad_fn=<MseLossBackward0>)\n",
            "epoch:  171 loss:  tensor(0.2527, grad_fn=<MseLossBackward0>)\n",
            "epoch:  172 loss:  tensor(0.2527, grad_fn=<MseLossBackward0>)\n",
            "epoch:  173 loss:  tensor(0.2526, grad_fn=<MseLossBackward0>)\n",
            "epoch:  174 loss:  tensor(0.2525, grad_fn=<MseLossBackward0>)\n",
            "epoch:  175 loss:  tensor(0.2524, grad_fn=<MseLossBackward0>)\n",
            "epoch:  176 loss:  tensor(0.2524, grad_fn=<MseLossBackward0>)\n",
            "epoch:  177 loss:  tensor(0.2523, grad_fn=<MseLossBackward0>)\n",
            "epoch:  178 loss:  tensor(0.2522, grad_fn=<MseLossBackward0>)\n",
            "epoch:  179 loss:  tensor(0.2521, grad_fn=<MseLossBackward0>)\n",
            "epoch:  180 loss:  tensor(0.2521, grad_fn=<MseLossBackward0>)\n",
            "epoch:  181 loss:  tensor(0.2520, grad_fn=<MseLossBackward0>)\n",
            "epoch:  182 loss:  tensor(0.2519, grad_fn=<MseLossBackward0>)\n",
            "epoch:  183 loss:  tensor(0.2519, grad_fn=<MseLossBackward0>)\n",
            "epoch:  184 loss:  tensor(0.2518, grad_fn=<MseLossBackward0>)\n",
            "epoch:  185 loss:  tensor(0.2517, grad_fn=<MseLossBackward0>)\n",
            "epoch:  186 loss:  tensor(0.2517, grad_fn=<MseLossBackward0>)\n",
            "epoch:  187 loss:  tensor(0.2516, grad_fn=<MseLossBackward0>)\n",
            "epoch:  188 loss:  tensor(0.2515, grad_fn=<MseLossBackward0>)\n",
            "epoch:  189 loss:  tensor(0.2514, grad_fn=<MseLossBackward0>)\n",
            "epoch:  190 loss:  tensor(0.2514, grad_fn=<MseLossBackward0>)\n",
            "epoch:  191 loss:  tensor(0.2513, grad_fn=<MseLossBackward0>)\n",
            "epoch:  192 loss:  tensor(0.2512, grad_fn=<MseLossBackward0>)\n",
            "epoch:  193 loss:  tensor(0.2512, grad_fn=<MseLossBackward0>)\n",
            "epoch:  194 loss:  tensor(0.2511, grad_fn=<MseLossBackward0>)\n",
            "epoch:  195 loss:  tensor(0.2510, grad_fn=<MseLossBackward0>)\n",
            "epoch:  196 loss:  tensor(0.2510, grad_fn=<MseLossBackward0>)\n",
            "epoch:  197 loss:  tensor(0.2509, grad_fn=<MseLossBackward0>)\n",
            "epoch:  198 loss:  tensor(0.2508, grad_fn=<MseLossBackward0>)\n",
            "epoch:  199 loss:  tensor(0.2508, grad_fn=<MseLossBackward0>)\n",
            "epoch:  200 loss:  tensor(0.2507, grad_fn=<MseLossBackward0>)\n",
            "epoch:  201 loss:  tensor(0.2506, grad_fn=<MseLossBackward0>)\n",
            "epoch:  202 loss:  tensor(0.2506, grad_fn=<MseLossBackward0>)\n",
            "epoch:  203 loss:  tensor(0.2505, grad_fn=<MseLossBackward0>)\n",
            "epoch:  204 loss:  tensor(0.2504, grad_fn=<MseLossBackward0>)\n",
            "epoch:  205 loss:  tensor(0.2504, grad_fn=<MseLossBackward0>)\n",
            "epoch:  206 loss:  tensor(0.2503, grad_fn=<MseLossBackward0>)\n",
            "epoch:  207 loss:  tensor(0.2502, grad_fn=<MseLossBackward0>)\n",
            "epoch:  208 loss:  tensor(0.2502, grad_fn=<MseLossBackward0>)\n",
            "epoch:  209 loss:  tensor(0.2501, grad_fn=<MseLossBackward0>)\n",
            "epoch:  210 loss:  tensor(0.2500, grad_fn=<MseLossBackward0>)\n",
            "epoch:  211 loss:  tensor(0.2500, grad_fn=<MseLossBackward0>)\n",
            "epoch:  212 loss:  tensor(0.2499, grad_fn=<MseLossBackward0>)\n",
            "epoch:  213 loss:  tensor(0.2498, grad_fn=<MseLossBackward0>)\n",
            "epoch:  214 loss:  tensor(0.2498, grad_fn=<MseLossBackward0>)\n",
            "epoch:  215 loss:  tensor(0.2497, grad_fn=<MseLossBackward0>)\n",
            "epoch:  216 loss:  tensor(0.2496, grad_fn=<MseLossBackward0>)\n",
            "epoch:  217 loss:  tensor(0.2496, grad_fn=<MseLossBackward0>)\n",
            "epoch:  218 loss:  tensor(0.2495, grad_fn=<MseLossBackward0>)\n",
            "epoch:  219 loss:  tensor(0.2494, grad_fn=<MseLossBackward0>)\n",
            "epoch:  220 loss:  tensor(0.2494, grad_fn=<MseLossBackward0>)\n",
            "epoch:  221 loss:  tensor(0.2493, grad_fn=<MseLossBackward0>)\n",
            "epoch:  222 loss:  tensor(0.2493, grad_fn=<MseLossBackward0>)\n",
            "epoch:  223 loss:  tensor(0.2492, grad_fn=<MseLossBackward0>)\n",
            "epoch:  224 loss:  tensor(0.2491, grad_fn=<MseLossBackward0>)\n",
            "epoch:  225 loss:  tensor(0.2491, grad_fn=<MseLossBackward0>)\n",
            "epoch:  226 loss:  tensor(0.2490, grad_fn=<MseLossBackward0>)\n",
            "epoch:  227 loss:  tensor(0.2489, grad_fn=<MseLossBackward0>)\n",
            "epoch:  228 loss:  tensor(0.2489, grad_fn=<MseLossBackward0>)\n",
            "epoch:  229 loss:  tensor(0.2488, grad_fn=<MseLossBackward0>)\n",
            "epoch:  230 loss:  tensor(0.2488, grad_fn=<MseLossBackward0>)\n",
            "epoch:  231 loss:  tensor(0.2487, grad_fn=<MseLossBackward0>)\n",
            "epoch:  232 loss:  tensor(0.2486, grad_fn=<MseLossBackward0>)\n",
            "epoch:  233 loss:  tensor(0.2486, grad_fn=<MseLossBackward0>)\n",
            "epoch:  234 loss:  tensor(0.2485, grad_fn=<MseLossBackward0>)\n",
            "epoch:  235 loss:  tensor(0.2484, grad_fn=<MseLossBackward0>)\n",
            "epoch:  236 loss:  tensor(0.2484, grad_fn=<MseLossBackward0>)\n",
            "epoch:  237 loss:  tensor(0.2483, grad_fn=<MseLossBackward0>)\n",
            "epoch:  238 loss:  tensor(0.2483, grad_fn=<MseLossBackward0>)\n",
            "epoch:  239 loss:  tensor(0.2482, grad_fn=<MseLossBackward0>)\n",
            "epoch:  240 loss:  tensor(0.2481, grad_fn=<MseLossBackward0>)\n",
            "epoch:  241 loss:  tensor(0.2481, grad_fn=<MseLossBackward0>)\n",
            "epoch:  242 loss:  tensor(0.2480, grad_fn=<MseLossBackward0>)\n",
            "epoch:  243 loss:  tensor(0.2480, grad_fn=<MseLossBackward0>)\n",
            "epoch:  244 loss:  tensor(0.2479, grad_fn=<MseLossBackward0>)\n",
            "epoch:  245 loss:  tensor(0.2478, grad_fn=<MseLossBackward0>)\n",
            "epoch:  246 loss:  tensor(0.2478, grad_fn=<MseLossBackward0>)\n",
            "epoch:  247 loss:  tensor(0.2477, grad_fn=<MseLossBackward0>)\n",
            "epoch:  248 loss:  tensor(0.2477, grad_fn=<MseLossBackward0>)\n",
            "epoch:  249 loss:  tensor(0.2476, grad_fn=<MseLossBackward0>)\n",
            "epoch:  250 loss:  tensor(0.2475, grad_fn=<MseLossBackward0>)\n",
            "epoch:  251 loss:  tensor(0.2475, grad_fn=<MseLossBackward0>)\n",
            "epoch:  252 loss:  tensor(0.2474, grad_fn=<MseLossBackward0>)\n",
            "epoch:  253 loss:  tensor(0.2474, grad_fn=<MseLossBackward0>)\n",
            "epoch:  254 loss:  tensor(0.2473, grad_fn=<MseLossBackward0>)\n",
            "epoch:  255 loss:  tensor(0.2473, grad_fn=<MseLossBackward0>)\n",
            "epoch:  256 loss:  tensor(0.2472, grad_fn=<MseLossBackward0>)\n",
            "epoch:  257 loss:  tensor(0.2472, grad_fn=<MseLossBackward0>)\n",
            "epoch:  258 loss:  tensor(0.2471, grad_fn=<MseLossBackward0>)\n",
            "epoch:  259 loss:  tensor(0.2470, grad_fn=<MseLossBackward0>)\n",
            "epoch:  260 loss:  tensor(0.2470, grad_fn=<MseLossBackward0>)\n",
            "epoch:  261 loss:  tensor(0.2469, grad_fn=<MseLossBackward0>)\n",
            "epoch:  262 loss:  tensor(0.2469, grad_fn=<MseLossBackward0>)\n",
            "epoch:  263 loss:  tensor(0.2468, grad_fn=<MseLossBackward0>)\n",
            "epoch:  264 loss:  tensor(0.2468, grad_fn=<MseLossBackward0>)\n",
            "epoch:  265 loss:  tensor(0.2467, grad_fn=<MseLossBackward0>)\n",
            "epoch:  266 loss:  tensor(0.2467, grad_fn=<MseLossBackward0>)\n",
            "epoch:  267 loss:  tensor(0.2466, grad_fn=<MseLossBackward0>)\n",
            "epoch:  268 loss:  tensor(0.2466, grad_fn=<MseLossBackward0>)\n",
            "epoch:  269 loss:  tensor(0.2465, grad_fn=<MseLossBackward0>)\n",
            "epoch:  270 loss:  tensor(0.2464, grad_fn=<MseLossBackward0>)\n",
            "epoch:  271 loss:  tensor(0.2464, grad_fn=<MseLossBackward0>)\n",
            "epoch:  272 loss:  tensor(0.2463, grad_fn=<MseLossBackward0>)\n",
            "epoch:  273 loss:  tensor(0.2463, grad_fn=<MseLossBackward0>)\n",
            "epoch:  274 loss:  tensor(0.2462, grad_fn=<MseLossBackward0>)\n",
            "epoch:  275 loss:  tensor(0.2462, grad_fn=<MseLossBackward0>)\n",
            "epoch:  276 loss:  tensor(0.2461, grad_fn=<MseLossBackward0>)\n",
            "epoch:  277 loss:  tensor(0.2461, grad_fn=<MseLossBackward0>)\n",
            "epoch:  278 loss:  tensor(0.2460, grad_fn=<MseLossBackward0>)\n",
            "epoch:  279 loss:  tensor(0.2460, grad_fn=<MseLossBackward0>)\n",
            "epoch:  280 loss:  tensor(0.2459, grad_fn=<MseLossBackward0>)\n",
            "epoch:  281 loss:  tensor(0.2459, grad_fn=<MseLossBackward0>)\n",
            "epoch:  282 loss:  tensor(0.2458, grad_fn=<MseLossBackward0>)\n",
            "epoch:  283 loss:  tensor(0.2458, grad_fn=<MseLossBackward0>)\n",
            "epoch:  284 loss:  tensor(0.2457, grad_fn=<MseLossBackward0>)\n",
            "epoch:  285 loss:  tensor(0.2457, grad_fn=<MseLossBackward0>)\n",
            "epoch:  286 loss:  tensor(0.2456, grad_fn=<MseLossBackward0>)\n",
            "epoch:  287 loss:  tensor(0.2456, grad_fn=<MseLossBackward0>)\n",
            "epoch:  288 loss:  tensor(0.2455, grad_fn=<MseLossBackward0>)\n",
            "epoch:  289 loss:  tensor(0.2455, grad_fn=<MseLossBackward0>)\n",
            "epoch:  290 loss:  tensor(0.2454, grad_fn=<MseLossBackward0>)\n",
            "epoch:  291 loss:  tensor(0.2454, grad_fn=<MseLossBackward0>)\n",
            "epoch:  292 loss:  tensor(0.2453, grad_fn=<MseLossBackward0>)\n",
            "epoch:  293 loss:  tensor(0.2453, grad_fn=<MseLossBackward0>)\n",
            "epoch:  294 loss:  tensor(0.2452, grad_fn=<MseLossBackward0>)\n",
            "epoch:  295 loss:  tensor(0.2452, grad_fn=<MseLossBackward0>)\n",
            "epoch:  296 loss:  tensor(0.2451, grad_fn=<MseLossBackward0>)\n",
            "epoch:  297 loss:  tensor(0.2451, grad_fn=<MseLossBackward0>)\n",
            "epoch:  298 loss:  tensor(0.2450, grad_fn=<MseLossBackward0>)\n",
            "epoch:  299 loss:  tensor(0.2450, grad_fn=<MseLossBackward0>)\n",
            "epoch:  300 loss:  tensor(0.2449, grad_fn=<MseLossBackward0>)\n",
            "epoch:  301 loss:  tensor(0.2449, grad_fn=<MseLossBackward0>)\n",
            "epoch:  302 loss:  tensor(0.2448, grad_fn=<MseLossBackward0>)\n",
            "epoch:  303 loss:  tensor(0.2448, grad_fn=<MseLossBackward0>)\n",
            "epoch:  304 loss:  tensor(0.2447, grad_fn=<MseLossBackward0>)\n",
            "epoch:  305 loss:  tensor(0.2447, grad_fn=<MseLossBackward0>)\n",
            "epoch:  306 loss:  tensor(0.2446, grad_fn=<MseLossBackward0>)\n",
            "epoch:  307 loss:  tensor(0.2446, grad_fn=<MseLossBackward0>)\n",
            "epoch:  308 loss:  tensor(0.2445, grad_fn=<MseLossBackward0>)\n",
            "epoch:  309 loss:  tensor(0.2445, grad_fn=<MseLossBackward0>)\n",
            "epoch:  310 loss:  tensor(0.2444, grad_fn=<MseLossBackward0>)\n",
            "epoch:  311 loss:  tensor(0.2444, grad_fn=<MseLossBackward0>)\n",
            "epoch:  312 loss:  tensor(0.2443, grad_fn=<MseLossBackward0>)\n",
            "epoch:  313 loss:  tensor(0.2443, grad_fn=<MseLossBackward0>)\n",
            "epoch:  314 loss:  tensor(0.2442, grad_fn=<MseLossBackward0>)\n",
            "epoch:  315 loss:  tensor(0.2442, grad_fn=<MseLossBackward0>)\n",
            "epoch:  316 loss:  tensor(0.2441, grad_fn=<MseLossBackward0>)\n",
            "epoch:  317 loss:  tensor(0.2441, grad_fn=<MseLossBackward0>)\n",
            "epoch:  318 loss:  tensor(0.2440, grad_fn=<MseLossBackward0>)\n",
            "epoch:  319 loss:  tensor(0.2440, grad_fn=<MseLossBackward0>)\n",
            "epoch:  320 loss:  tensor(0.2439, grad_fn=<MseLossBackward0>)\n",
            "epoch:  321 loss:  tensor(0.2439, grad_fn=<MseLossBackward0>)\n",
            "epoch:  322 loss:  tensor(0.2438, grad_fn=<MseLossBackward0>)\n",
            "epoch:  323 loss:  tensor(0.2438, grad_fn=<MseLossBackward0>)\n",
            "epoch:  324 loss:  tensor(0.2437, grad_fn=<MseLossBackward0>)\n",
            "epoch:  325 loss:  tensor(0.2437, grad_fn=<MseLossBackward0>)\n",
            "epoch:  326 loss:  tensor(0.2437, grad_fn=<MseLossBackward0>)\n",
            "epoch:  327 loss:  tensor(0.2436, grad_fn=<MseLossBackward0>)\n",
            "epoch:  328 loss:  tensor(0.2436, grad_fn=<MseLossBackward0>)\n",
            "epoch:  329 loss:  tensor(0.2435, grad_fn=<MseLossBackward0>)\n",
            "epoch:  330 loss:  tensor(0.2435, grad_fn=<MseLossBackward0>)\n",
            "epoch:  331 loss:  tensor(0.2434, grad_fn=<MseLossBackward0>)\n",
            "epoch:  332 loss:  tensor(0.2434, grad_fn=<MseLossBackward0>)\n",
            "epoch:  333 loss:  tensor(0.2433, grad_fn=<MseLossBackward0>)\n",
            "epoch:  334 loss:  tensor(0.2433, grad_fn=<MseLossBackward0>)\n",
            "epoch:  335 loss:  tensor(0.2432, grad_fn=<MseLossBackward0>)\n",
            "epoch:  336 loss:  tensor(0.2432, grad_fn=<MseLossBackward0>)\n",
            "epoch:  337 loss:  tensor(0.2431, grad_fn=<MseLossBackward0>)\n",
            "epoch:  338 loss:  tensor(0.2431, grad_fn=<MseLossBackward0>)\n",
            "epoch:  339 loss:  tensor(0.2431, grad_fn=<MseLossBackward0>)\n",
            "epoch:  340 loss:  tensor(0.2430, grad_fn=<MseLossBackward0>)\n",
            "epoch:  341 loss:  tensor(0.2430, grad_fn=<MseLossBackward0>)\n",
            "epoch:  342 loss:  tensor(0.2429, grad_fn=<MseLossBackward0>)\n",
            "epoch:  343 loss:  tensor(0.2429, grad_fn=<MseLossBackward0>)\n",
            "epoch:  344 loss:  tensor(0.2428, grad_fn=<MseLossBackward0>)\n",
            "epoch:  345 loss:  tensor(0.2428, grad_fn=<MseLossBackward0>)\n",
            "epoch:  346 loss:  tensor(0.2427, grad_fn=<MseLossBackward0>)\n",
            "epoch:  347 loss:  tensor(0.2427, grad_fn=<MseLossBackward0>)\n",
            "epoch:  348 loss:  tensor(0.2426, grad_fn=<MseLossBackward0>)\n",
            "epoch:  349 loss:  tensor(0.2426, grad_fn=<MseLossBackward0>)\n",
            "epoch:  350 loss:  tensor(0.2426, grad_fn=<MseLossBackward0>)\n",
            "epoch:  351 loss:  tensor(0.2425, grad_fn=<MseLossBackward0>)\n",
            "epoch:  352 loss:  tensor(0.2425, grad_fn=<MseLossBackward0>)\n",
            "epoch:  353 loss:  tensor(0.2424, grad_fn=<MseLossBackward0>)\n",
            "epoch:  354 loss:  tensor(0.2424, grad_fn=<MseLossBackward0>)\n",
            "epoch:  355 loss:  tensor(0.2423, grad_fn=<MseLossBackward0>)\n",
            "epoch:  356 loss:  tensor(0.2423, grad_fn=<MseLossBackward0>)\n",
            "epoch:  357 loss:  tensor(0.2423, grad_fn=<MseLossBackward0>)\n",
            "epoch:  358 loss:  tensor(0.2422, grad_fn=<MseLossBackward0>)\n",
            "epoch:  359 loss:  tensor(0.2422, grad_fn=<MseLossBackward0>)\n",
            "epoch:  360 loss:  tensor(0.2421, grad_fn=<MseLossBackward0>)\n",
            "epoch:  361 loss:  tensor(0.2421, grad_fn=<MseLossBackward0>)\n",
            "epoch:  362 loss:  tensor(0.2420, grad_fn=<MseLossBackward0>)\n",
            "epoch:  363 loss:  tensor(0.2420, grad_fn=<MseLossBackward0>)\n",
            "epoch:  364 loss:  tensor(0.2419, grad_fn=<MseLossBackward0>)\n",
            "epoch:  365 loss:  tensor(0.2419, grad_fn=<MseLossBackward0>)\n",
            "epoch:  366 loss:  tensor(0.2419, grad_fn=<MseLossBackward0>)\n",
            "epoch:  367 loss:  tensor(0.2418, grad_fn=<MseLossBackward0>)\n",
            "epoch:  368 loss:  tensor(0.2418, grad_fn=<MseLossBackward0>)\n",
            "epoch:  369 loss:  tensor(0.2417, grad_fn=<MseLossBackward0>)\n",
            "epoch:  370 loss:  tensor(0.2417, grad_fn=<MseLossBackward0>)\n",
            "epoch:  371 loss:  tensor(0.2416, grad_fn=<MseLossBackward0>)\n",
            "epoch:  372 loss:  tensor(0.2416, grad_fn=<MseLossBackward0>)\n",
            "epoch:  373 loss:  tensor(0.2416, grad_fn=<MseLossBackward0>)\n",
            "epoch:  374 loss:  tensor(0.2415, grad_fn=<MseLossBackward0>)\n",
            "epoch:  375 loss:  tensor(0.2415, grad_fn=<MseLossBackward0>)\n",
            "epoch:  376 loss:  tensor(0.2414, grad_fn=<MseLossBackward0>)\n",
            "epoch:  377 loss:  tensor(0.2414, grad_fn=<MseLossBackward0>)\n",
            "epoch:  378 loss:  tensor(0.2413, grad_fn=<MseLossBackward0>)\n",
            "epoch:  379 loss:  tensor(0.2413, grad_fn=<MseLossBackward0>)\n",
            "epoch:  380 loss:  tensor(0.2413, grad_fn=<MseLossBackward0>)\n",
            "epoch:  381 loss:  tensor(0.2412, grad_fn=<MseLossBackward0>)\n",
            "epoch:  382 loss:  tensor(0.2412, grad_fn=<MseLossBackward0>)\n",
            "epoch:  383 loss:  tensor(0.2411, grad_fn=<MseLossBackward0>)\n",
            "epoch:  384 loss:  tensor(0.2411, grad_fn=<MseLossBackward0>)\n",
            "epoch:  385 loss:  tensor(0.2411, grad_fn=<MseLossBackward0>)\n",
            "epoch:  386 loss:  tensor(0.2410, grad_fn=<MseLossBackward0>)\n",
            "epoch:  387 loss:  tensor(0.2410, grad_fn=<MseLossBackward0>)\n",
            "epoch:  388 loss:  tensor(0.2409, grad_fn=<MseLossBackward0>)\n",
            "epoch:  389 loss:  tensor(0.2409, grad_fn=<MseLossBackward0>)\n",
            "epoch:  390 loss:  tensor(0.2408, grad_fn=<MseLossBackward0>)\n",
            "epoch:  391 loss:  tensor(0.2408, grad_fn=<MseLossBackward0>)\n",
            "epoch:  392 loss:  tensor(0.2408, grad_fn=<MseLossBackward0>)\n",
            "epoch:  393 loss:  tensor(0.2407, grad_fn=<MseLossBackward0>)\n",
            "epoch:  394 loss:  tensor(0.2407, grad_fn=<MseLossBackward0>)\n",
            "epoch:  395 loss:  tensor(0.2406, grad_fn=<MseLossBackward0>)\n",
            "epoch:  396 loss:  tensor(0.2406, grad_fn=<MseLossBackward0>)\n",
            "epoch:  397 loss:  tensor(0.2406, grad_fn=<MseLossBackward0>)\n",
            "epoch:  398 loss:  tensor(0.2405, grad_fn=<MseLossBackward0>)\n",
            "epoch:  399 loss:  tensor(0.2405, grad_fn=<MseLossBackward0>)\n",
            "epoch:  400 loss:  tensor(0.2404, grad_fn=<MseLossBackward0>)\n",
            "epoch:  401 loss:  tensor(0.2404, grad_fn=<MseLossBackward0>)\n",
            "epoch:  402 loss:  tensor(0.2404, grad_fn=<MseLossBackward0>)\n",
            "epoch:  403 loss:  tensor(0.2403, grad_fn=<MseLossBackward0>)\n",
            "epoch:  404 loss:  tensor(0.2403, grad_fn=<MseLossBackward0>)\n",
            "epoch:  405 loss:  tensor(0.2402, grad_fn=<MseLossBackward0>)\n",
            "epoch:  406 loss:  tensor(0.2402, grad_fn=<MseLossBackward0>)\n",
            "epoch:  407 loss:  tensor(0.2402, grad_fn=<MseLossBackward0>)\n",
            "epoch:  408 loss:  tensor(0.2401, grad_fn=<MseLossBackward0>)\n",
            "epoch:  409 loss:  tensor(0.2401, grad_fn=<MseLossBackward0>)\n",
            "epoch:  410 loss:  tensor(0.2400, grad_fn=<MseLossBackward0>)\n",
            "epoch:  411 loss:  tensor(0.2400, grad_fn=<MseLossBackward0>)\n",
            "epoch:  412 loss:  tensor(0.2400, grad_fn=<MseLossBackward0>)\n",
            "epoch:  413 loss:  tensor(0.2399, grad_fn=<MseLossBackward0>)\n",
            "epoch:  414 loss:  tensor(0.2399, grad_fn=<MseLossBackward0>)\n",
            "epoch:  415 loss:  tensor(0.2398, grad_fn=<MseLossBackward0>)\n",
            "epoch:  416 loss:  tensor(0.2398, grad_fn=<MseLossBackward0>)\n",
            "epoch:  417 loss:  tensor(0.2398, grad_fn=<MseLossBackward0>)\n",
            "epoch:  418 loss:  tensor(0.2397, grad_fn=<MseLossBackward0>)\n",
            "epoch:  419 loss:  tensor(0.2397, grad_fn=<MseLossBackward0>)\n",
            "epoch:  420 loss:  tensor(0.2396, grad_fn=<MseLossBackward0>)\n",
            "epoch:  421 loss:  tensor(0.2396, grad_fn=<MseLossBackward0>)\n",
            "epoch:  422 loss:  tensor(0.2396, grad_fn=<MseLossBackward0>)\n",
            "epoch:  423 loss:  tensor(0.2395, grad_fn=<MseLossBackward0>)\n",
            "epoch:  424 loss:  tensor(0.2395, grad_fn=<MseLossBackward0>)\n",
            "epoch:  425 loss:  tensor(0.2394, grad_fn=<MseLossBackward0>)\n",
            "epoch:  426 loss:  tensor(0.2394, grad_fn=<MseLossBackward0>)\n",
            "epoch:  427 loss:  tensor(0.2394, grad_fn=<MseLossBackward0>)\n",
            "epoch:  428 loss:  tensor(0.2393, grad_fn=<MseLossBackward0>)\n",
            "epoch:  429 loss:  tensor(0.2393, grad_fn=<MseLossBackward0>)\n",
            "epoch:  430 loss:  tensor(0.2393, grad_fn=<MseLossBackward0>)\n",
            "epoch:  431 loss:  tensor(0.2392, grad_fn=<MseLossBackward0>)\n",
            "epoch:  432 loss:  tensor(0.2392, grad_fn=<MseLossBackward0>)\n",
            "epoch:  433 loss:  tensor(0.2391, grad_fn=<MseLossBackward0>)\n",
            "epoch:  434 loss:  tensor(0.2391, grad_fn=<MseLossBackward0>)\n",
            "epoch:  435 loss:  tensor(0.2391, grad_fn=<MseLossBackward0>)\n",
            "epoch:  436 loss:  tensor(0.2390, grad_fn=<MseLossBackward0>)\n",
            "epoch:  437 loss:  tensor(0.2390, grad_fn=<MseLossBackward0>)\n",
            "epoch:  438 loss:  tensor(0.2389, grad_fn=<MseLossBackward0>)\n",
            "epoch:  439 loss:  tensor(0.2389, grad_fn=<MseLossBackward0>)\n",
            "epoch:  440 loss:  tensor(0.2389, grad_fn=<MseLossBackward0>)\n",
            "epoch:  441 loss:  tensor(0.2388, grad_fn=<MseLossBackward0>)\n",
            "epoch:  442 loss:  tensor(0.2388, grad_fn=<MseLossBackward0>)\n",
            "epoch:  443 loss:  tensor(0.2388, grad_fn=<MseLossBackward0>)\n",
            "epoch:  444 loss:  tensor(0.2387, grad_fn=<MseLossBackward0>)\n",
            "epoch:  445 loss:  tensor(0.2387, grad_fn=<MseLossBackward0>)\n",
            "epoch:  446 loss:  tensor(0.2387, grad_fn=<MseLossBackward0>)\n",
            "epoch:  447 loss:  tensor(0.2386, grad_fn=<MseLossBackward0>)\n",
            "epoch:  448 loss:  tensor(0.2386, grad_fn=<MseLossBackward0>)\n",
            "epoch:  449 loss:  tensor(0.2386, grad_fn=<MseLossBackward0>)\n",
            "epoch:  450 loss:  tensor(0.2385, grad_fn=<MseLossBackward0>)\n",
            "epoch:  451 loss:  tensor(0.2385, grad_fn=<MseLossBackward0>)\n",
            "epoch:  452 loss:  tensor(0.2385, grad_fn=<MseLossBackward0>)\n",
            "epoch:  453 loss:  tensor(0.2385, grad_fn=<MseLossBackward0>)\n",
            "epoch:  454 loss:  tensor(0.2384, grad_fn=<MseLossBackward0>)\n",
            "epoch:  455 loss:  tensor(0.2384, grad_fn=<MseLossBackward0>)\n",
            "epoch:  456 loss:  tensor(0.2384, grad_fn=<MseLossBackward0>)\n",
            "epoch:  457 loss:  tensor(0.2383, grad_fn=<MseLossBackward0>)\n",
            "epoch:  458 loss:  tensor(0.2383, grad_fn=<MseLossBackward0>)\n",
            "epoch:  459 loss:  tensor(0.2383, grad_fn=<MseLossBackward0>)\n",
            "epoch:  460 loss:  tensor(0.2382, grad_fn=<MseLossBackward0>)\n",
            "epoch:  461 loss:  tensor(0.2382, grad_fn=<MseLossBackward0>)\n",
            "epoch:  462 loss:  tensor(0.2382, grad_fn=<MseLossBackward0>)\n",
            "epoch:  463 loss:  tensor(0.2382, grad_fn=<MseLossBackward0>)\n",
            "epoch:  464 loss:  tensor(0.2381, grad_fn=<MseLossBackward0>)\n",
            "epoch:  465 loss:  tensor(0.2381, grad_fn=<MseLossBackward0>)\n",
            "epoch:  466 loss:  tensor(0.2381, grad_fn=<MseLossBackward0>)\n",
            "epoch:  467 loss:  tensor(0.2380, grad_fn=<MseLossBackward0>)\n",
            "epoch:  468 loss:  tensor(0.2380, grad_fn=<MseLossBackward0>)\n",
            "epoch:  469 loss:  tensor(0.2380, grad_fn=<MseLossBackward0>)\n",
            "epoch:  470 loss:  tensor(0.2379, grad_fn=<MseLossBackward0>)\n",
            "epoch:  471 loss:  tensor(0.2379, grad_fn=<MseLossBackward0>)\n",
            "epoch:  472 loss:  tensor(0.2379, grad_fn=<MseLossBackward0>)\n",
            "epoch:  473 loss:  tensor(0.2379, grad_fn=<MseLossBackward0>)\n",
            "epoch:  474 loss:  tensor(0.2378, grad_fn=<MseLossBackward0>)\n",
            "epoch:  475 loss:  tensor(0.2378, grad_fn=<MseLossBackward0>)\n",
            "epoch:  476 loss:  tensor(0.2378, grad_fn=<MseLossBackward0>)\n",
            "epoch:  477 loss:  tensor(0.2377, grad_fn=<MseLossBackward0>)\n",
            "epoch:  478 loss:  tensor(0.2377, grad_fn=<MseLossBackward0>)\n",
            "epoch:  479 loss:  tensor(0.2377, grad_fn=<MseLossBackward0>)\n",
            "epoch:  480 loss:  tensor(0.2376, grad_fn=<MseLossBackward0>)\n",
            "epoch:  481 loss:  tensor(0.2376, grad_fn=<MseLossBackward0>)\n",
            "epoch:  482 loss:  tensor(0.2376, grad_fn=<MseLossBackward0>)\n",
            "epoch:  483 loss:  tensor(0.2376, grad_fn=<MseLossBackward0>)\n",
            "epoch:  484 loss:  tensor(0.2375, grad_fn=<MseLossBackward0>)\n",
            "epoch:  485 loss:  tensor(0.2375, grad_fn=<MseLossBackward0>)\n",
            "epoch:  486 loss:  tensor(0.2375, grad_fn=<MseLossBackward0>)\n",
            "epoch:  487 loss:  tensor(0.2374, grad_fn=<MseLossBackward0>)\n",
            "epoch:  488 loss:  tensor(0.2374, grad_fn=<MseLossBackward0>)\n",
            "epoch:  489 loss:  tensor(0.2374, grad_fn=<MseLossBackward0>)\n",
            "epoch:  490 loss:  tensor(0.2374, grad_fn=<MseLossBackward0>)\n",
            "epoch:  491 loss:  tensor(0.2373, grad_fn=<MseLossBackward0>)\n",
            "epoch:  492 loss:  tensor(0.2373, grad_fn=<MseLossBackward0>)\n",
            "epoch:  493 loss:  tensor(0.2373, grad_fn=<MseLossBackward0>)\n",
            "epoch:  494 loss:  tensor(0.2372, grad_fn=<MseLossBackward0>)\n",
            "epoch:  495 loss:  tensor(0.2372, grad_fn=<MseLossBackward0>)\n",
            "epoch:  496 loss:  tensor(0.2372, grad_fn=<MseLossBackward0>)\n",
            "epoch:  497 loss:  tensor(0.2372, grad_fn=<MseLossBackward0>)\n",
            "epoch:  498 loss:  tensor(0.2371, grad_fn=<MseLossBackward0>)\n",
            "epoch:  499 loss:  tensor(0.2371, grad_fn=<MseLossBackward0>)\n",
            "epoch:  500 loss:  tensor(0.2371, grad_fn=<MseLossBackward0>)\n",
            "epoch:  501 loss:  tensor(0.2370, grad_fn=<MseLossBackward0>)\n",
            "epoch:  502 loss:  tensor(0.2370, grad_fn=<MseLossBackward0>)\n",
            "epoch:  503 loss:  tensor(0.2370, grad_fn=<MseLossBackward0>)\n",
            "epoch:  504 loss:  tensor(0.2370, grad_fn=<MseLossBackward0>)\n",
            "epoch:  505 loss:  tensor(0.2369, grad_fn=<MseLossBackward0>)\n",
            "epoch:  506 loss:  tensor(0.2369, grad_fn=<MseLossBackward0>)\n",
            "epoch:  507 loss:  tensor(0.2369, grad_fn=<MseLossBackward0>)\n",
            "epoch:  508 loss:  tensor(0.2368, grad_fn=<MseLossBackward0>)\n",
            "epoch:  509 loss:  tensor(0.2368, grad_fn=<MseLossBackward0>)\n",
            "epoch:  510 loss:  tensor(0.2368, grad_fn=<MseLossBackward0>)\n",
            "epoch:  511 loss:  tensor(0.2368, grad_fn=<MseLossBackward0>)\n",
            "epoch:  512 loss:  tensor(0.2367, grad_fn=<MseLossBackward0>)\n",
            "epoch:  513 loss:  tensor(0.2367, grad_fn=<MseLossBackward0>)\n",
            "epoch:  514 loss:  tensor(0.2367, grad_fn=<MseLossBackward0>)\n",
            "epoch:  515 loss:  tensor(0.2366, grad_fn=<MseLossBackward0>)\n",
            "epoch:  516 loss:  tensor(0.2366, grad_fn=<MseLossBackward0>)\n",
            "epoch:  517 loss:  tensor(0.2366, grad_fn=<MseLossBackward0>)\n",
            "epoch:  518 loss:  tensor(0.2366, grad_fn=<MseLossBackward0>)\n",
            "epoch:  519 loss:  tensor(0.2365, grad_fn=<MseLossBackward0>)\n",
            "epoch:  520 loss:  tensor(0.2365, grad_fn=<MseLossBackward0>)\n",
            "epoch:  521 loss:  tensor(0.2365, grad_fn=<MseLossBackward0>)\n",
            "epoch:  522 loss:  tensor(0.2364, grad_fn=<MseLossBackward0>)\n",
            "epoch:  523 loss:  tensor(0.2364, grad_fn=<MseLossBackward0>)\n",
            "epoch:  524 loss:  tensor(0.2364, grad_fn=<MseLossBackward0>)\n",
            "epoch:  525 loss:  tensor(0.2364, grad_fn=<MseLossBackward0>)\n",
            "epoch:  526 loss:  tensor(0.2363, grad_fn=<MseLossBackward0>)\n",
            "epoch:  527 loss:  tensor(0.2363, grad_fn=<MseLossBackward0>)\n",
            "epoch:  528 loss:  tensor(0.2363, grad_fn=<MseLossBackward0>)\n",
            "epoch:  529 loss:  tensor(0.2362, grad_fn=<MseLossBackward0>)\n",
            "epoch:  530 loss:  tensor(0.2362, grad_fn=<MseLossBackward0>)\n",
            "epoch:  531 loss:  tensor(0.2362, grad_fn=<MseLossBackward0>)\n",
            "epoch:  532 loss:  tensor(0.2362, grad_fn=<MseLossBackward0>)\n",
            "epoch:  533 loss:  tensor(0.2361, grad_fn=<MseLossBackward0>)\n",
            "epoch:  534 loss:  tensor(0.2361, grad_fn=<MseLossBackward0>)\n",
            "epoch:  535 loss:  tensor(0.2361, grad_fn=<MseLossBackward0>)\n",
            "epoch:  536 loss:  tensor(0.2361, grad_fn=<MseLossBackward0>)\n",
            "epoch:  537 loss:  tensor(0.2360, grad_fn=<MseLossBackward0>)\n",
            "epoch:  538 loss:  tensor(0.2360, grad_fn=<MseLossBackward0>)\n",
            "epoch:  539 loss:  tensor(0.2360, grad_fn=<MseLossBackward0>)\n",
            "epoch:  540 loss:  tensor(0.2359, grad_fn=<MseLossBackward0>)\n",
            "epoch:  541 loss:  tensor(0.2359, grad_fn=<MseLossBackward0>)\n",
            "epoch:  542 loss:  tensor(0.2359, grad_fn=<MseLossBackward0>)\n",
            "epoch:  543 loss:  tensor(0.2359, grad_fn=<MseLossBackward0>)\n",
            "epoch:  544 loss:  tensor(0.2358, grad_fn=<MseLossBackward0>)\n",
            "epoch:  545 loss:  tensor(0.2358, grad_fn=<MseLossBackward0>)\n",
            "epoch:  546 loss:  tensor(0.2358, grad_fn=<MseLossBackward0>)\n",
            "epoch:  547 loss:  tensor(0.2358, grad_fn=<MseLossBackward0>)\n",
            "epoch:  548 loss:  tensor(0.2357, grad_fn=<MseLossBackward0>)\n",
            "epoch:  549 loss:  tensor(0.2357, grad_fn=<MseLossBackward0>)\n",
            "epoch:  550 loss:  tensor(0.2357, grad_fn=<MseLossBackward0>)\n",
            "epoch:  551 loss:  tensor(0.2356, grad_fn=<MseLossBackward0>)\n",
            "epoch:  552 loss:  tensor(0.2356, grad_fn=<MseLossBackward0>)\n",
            "epoch:  553 loss:  tensor(0.2356, grad_fn=<MseLossBackward0>)\n",
            "epoch:  554 loss:  tensor(0.2356, grad_fn=<MseLossBackward0>)\n",
            "epoch:  555 loss:  tensor(0.2355, grad_fn=<MseLossBackward0>)\n",
            "epoch:  556 loss:  tensor(0.2355, grad_fn=<MseLossBackward0>)\n",
            "epoch:  557 loss:  tensor(0.2355, grad_fn=<MseLossBackward0>)\n",
            "epoch:  558 loss:  tensor(0.2355, grad_fn=<MseLossBackward0>)\n",
            "epoch:  559 loss:  tensor(0.2354, grad_fn=<MseLossBackward0>)\n",
            "epoch:  560 loss:  tensor(0.2354, grad_fn=<MseLossBackward0>)\n",
            "epoch:  561 loss:  tensor(0.2354, grad_fn=<MseLossBackward0>)\n",
            "epoch:  562 loss:  tensor(0.2353, grad_fn=<MseLossBackward0>)\n",
            "epoch:  563 loss:  tensor(0.2353, grad_fn=<MseLossBackward0>)\n",
            "epoch:  564 loss:  tensor(0.2353, grad_fn=<MseLossBackward0>)\n",
            "epoch:  565 loss:  tensor(0.2353, grad_fn=<MseLossBackward0>)\n",
            "epoch:  566 loss:  tensor(0.2352, grad_fn=<MseLossBackward0>)\n",
            "epoch:  567 loss:  tensor(0.2352, grad_fn=<MseLossBackward0>)\n",
            "epoch:  568 loss:  tensor(0.2352, grad_fn=<MseLossBackward0>)\n",
            "epoch:  569 loss:  tensor(0.2352, grad_fn=<MseLossBackward0>)\n",
            "epoch:  570 loss:  tensor(0.2351, grad_fn=<MseLossBackward0>)\n",
            "epoch:  571 loss:  tensor(0.2351, grad_fn=<MseLossBackward0>)\n",
            "epoch:  572 loss:  tensor(0.2351, grad_fn=<MseLossBackward0>)\n",
            "epoch:  573 loss:  tensor(0.2350, grad_fn=<MseLossBackward0>)\n",
            "epoch:  574 loss:  tensor(0.2350, grad_fn=<MseLossBackward0>)\n",
            "epoch:  575 loss:  tensor(0.2350, grad_fn=<MseLossBackward0>)\n",
            "epoch:  576 loss:  tensor(0.2350, grad_fn=<MseLossBackward0>)\n",
            "epoch:  577 loss:  tensor(0.2349, grad_fn=<MseLossBackward0>)\n",
            "epoch:  578 loss:  tensor(0.2349, grad_fn=<MseLossBackward0>)\n",
            "epoch:  579 loss:  tensor(0.2349, grad_fn=<MseLossBackward0>)\n",
            "epoch:  580 loss:  tensor(0.2349, grad_fn=<MseLossBackward0>)\n",
            "epoch:  581 loss:  tensor(0.2348, grad_fn=<MseLossBackward0>)\n",
            "epoch:  582 loss:  tensor(0.2348, grad_fn=<MseLossBackward0>)\n",
            "epoch:  583 loss:  tensor(0.2348, grad_fn=<MseLossBackward0>)\n",
            "epoch:  584 loss:  tensor(0.2348, grad_fn=<MseLossBackward0>)\n",
            "epoch:  585 loss:  tensor(0.2347, grad_fn=<MseLossBackward0>)\n",
            "epoch:  586 loss:  tensor(0.2347, grad_fn=<MseLossBackward0>)\n",
            "epoch:  587 loss:  tensor(0.2347, grad_fn=<MseLossBackward0>)\n",
            "epoch:  588 loss:  tensor(0.2346, grad_fn=<MseLossBackward0>)\n",
            "epoch:  589 loss:  tensor(0.2346, grad_fn=<MseLossBackward0>)\n",
            "epoch:  590 loss:  tensor(0.2346, grad_fn=<MseLossBackward0>)\n",
            "epoch:  591 loss:  tensor(0.2346, grad_fn=<MseLossBackward0>)\n",
            "epoch:  592 loss:  tensor(0.2345, grad_fn=<MseLossBackward0>)\n",
            "epoch:  593 loss:  tensor(0.2345, grad_fn=<MseLossBackward0>)\n",
            "epoch:  594 loss:  tensor(0.2345, grad_fn=<MseLossBackward0>)\n",
            "epoch:  595 loss:  tensor(0.2345, grad_fn=<MseLossBackward0>)\n",
            "epoch:  596 loss:  tensor(0.2344, grad_fn=<MseLossBackward0>)\n",
            "epoch:  597 loss:  tensor(0.2344, grad_fn=<MseLossBackward0>)\n",
            "epoch:  598 loss:  tensor(0.2344, grad_fn=<MseLossBackward0>)\n",
            "epoch:  599 loss:  tensor(0.2344, grad_fn=<MseLossBackward0>)\n",
            "epoch:  600 loss:  tensor(0.2343, grad_fn=<MseLossBackward0>)\n",
            "epoch:  601 loss:  tensor(0.2343, grad_fn=<MseLossBackward0>)\n",
            "epoch:  602 loss:  tensor(0.2343, grad_fn=<MseLossBackward0>)\n",
            "epoch:  603 loss:  tensor(0.2342, grad_fn=<MseLossBackward0>)\n",
            "epoch:  604 loss:  tensor(0.2342, grad_fn=<MseLossBackward0>)\n",
            "epoch:  605 loss:  tensor(0.2342, grad_fn=<MseLossBackward0>)\n",
            "epoch:  606 loss:  tensor(0.2342, grad_fn=<MseLossBackward0>)\n",
            "epoch:  607 loss:  tensor(0.2341, grad_fn=<MseLossBackward0>)\n",
            "epoch:  608 loss:  tensor(0.2341, grad_fn=<MseLossBackward0>)\n",
            "epoch:  609 loss:  tensor(0.2341, grad_fn=<MseLossBackward0>)\n",
            "epoch:  610 loss:  tensor(0.2341, grad_fn=<MseLossBackward0>)\n",
            "epoch:  611 loss:  tensor(0.2340, grad_fn=<MseLossBackward0>)\n",
            "epoch:  612 loss:  tensor(0.2340, grad_fn=<MseLossBackward0>)\n",
            "epoch:  613 loss:  tensor(0.2340, grad_fn=<MseLossBackward0>)\n",
            "epoch:  614 loss:  tensor(0.2340, grad_fn=<MseLossBackward0>)\n",
            "epoch:  615 loss:  tensor(0.2339, grad_fn=<MseLossBackward0>)\n",
            "epoch:  616 loss:  tensor(0.2339, grad_fn=<MseLossBackward0>)\n",
            "epoch:  617 loss:  tensor(0.2339, grad_fn=<MseLossBackward0>)\n",
            "epoch:  618 loss:  tensor(0.2339, grad_fn=<MseLossBackward0>)\n",
            "epoch:  619 loss:  tensor(0.2338, grad_fn=<MseLossBackward0>)\n",
            "epoch:  620 loss:  tensor(0.2338, grad_fn=<MseLossBackward0>)\n",
            "epoch:  621 loss:  tensor(0.2338, grad_fn=<MseLossBackward0>)\n",
            "epoch:  622 loss:  tensor(0.2337, grad_fn=<MseLossBackward0>)\n",
            "epoch:  623 loss:  tensor(0.2337, grad_fn=<MseLossBackward0>)\n",
            "epoch:  624 loss:  tensor(0.2337, grad_fn=<MseLossBackward0>)\n",
            "epoch:  625 loss:  tensor(0.2337, grad_fn=<MseLossBackward0>)\n",
            "epoch:  626 loss:  tensor(0.2336, grad_fn=<MseLossBackward0>)\n",
            "epoch:  627 loss:  tensor(0.2336, grad_fn=<MseLossBackward0>)\n",
            "epoch:  628 loss:  tensor(0.2336, grad_fn=<MseLossBackward0>)\n",
            "epoch:  629 loss:  tensor(0.2336, grad_fn=<MseLossBackward0>)\n",
            "epoch:  630 loss:  tensor(0.2335, grad_fn=<MseLossBackward0>)\n",
            "epoch:  631 loss:  tensor(0.2335, grad_fn=<MseLossBackward0>)\n",
            "epoch:  632 loss:  tensor(0.2335, grad_fn=<MseLossBackward0>)\n",
            "epoch:  633 loss:  tensor(0.2335, grad_fn=<MseLossBackward0>)\n",
            "epoch:  634 loss:  tensor(0.2334, grad_fn=<MseLossBackward0>)\n",
            "epoch:  635 loss:  tensor(0.2334, grad_fn=<MseLossBackward0>)\n",
            "epoch:  636 loss:  tensor(0.2334, grad_fn=<MseLossBackward0>)\n",
            "epoch:  637 loss:  tensor(0.2333, grad_fn=<MseLossBackward0>)\n",
            "epoch:  638 loss:  tensor(0.2333, grad_fn=<MseLossBackward0>)\n",
            "epoch:  639 loss:  tensor(0.2333, grad_fn=<MseLossBackward0>)\n",
            "epoch:  640 loss:  tensor(0.2333, grad_fn=<MseLossBackward0>)\n",
            "epoch:  641 loss:  tensor(0.2332, grad_fn=<MseLossBackward0>)\n",
            "epoch:  642 loss:  tensor(0.2332, grad_fn=<MseLossBackward0>)\n",
            "epoch:  643 loss:  tensor(0.2332, grad_fn=<MseLossBackward0>)\n",
            "epoch:  644 loss:  tensor(0.2332, grad_fn=<MseLossBackward0>)\n",
            "epoch:  645 loss:  tensor(0.2331, grad_fn=<MseLossBackward0>)\n",
            "epoch:  646 loss:  tensor(0.2331, grad_fn=<MseLossBackward0>)\n",
            "epoch:  647 loss:  tensor(0.2331, grad_fn=<MseLossBackward0>)\n",
            "epoch:  648 loss:  tensor(0.2331, grad_fn=<MseLossBackward0>)\n",
            "epoch:  649 loss:  tensor(0.2330, grad_fn=<MseLossBackward0>)\n",
            "epoch:  650 loss:  tensor(0.2330, grad_fn=<MseLossBackward0>)\n",
            "epoch:  651 loss:  tensor(0.2330, grad_fn=<MseLossBackward0>)\n",
            "epoch:  652 loss:  tensor(0.2330, grad_fn=<MseLossBackward0>)\n",
            "epoch:  653 loss:  tensor(0.2329, grad_fn=<MseLossBackward0>)\n",
            "epoch:  654 loss:  tensor(0.2329, grad_fn=<MseLossBackward0>)\n",
            "epoch:  655 loss:  tensor(0.2329, grad_fn=<MseLossBackward0>)\n",
            "epoch:  656 loss:  tensor(0.2328, grad_fn=<MseLossBackward0>)\n",
            "epoch:  657 loss:  tensor(0.2328, grad_fn=<MseLossBackward0>)\n",
            "epoch:  658 loss:  tensor(0.2328, grad_fn=<MseLossBackward0>)\n",
            "epoch:  659 loss:  tensor(0.2328, grad_fn=<MseLossBackward0>)\n",
            "epoch:  660 loss:  tensor(0.2327, grad_fn=<MseLossBackward0>)\n",
            "epoch:  661 loss:  tensor(0.2327, grad_fn=<MseLossBackward0>)\n",
            "epoch:  662 loss:  tensor(0.2327, grad_fn=<MseLossBackward0>)\n",
            "epoch:  663 loss:  tensor(0.2327, grad_fn=<MseLossBackward0>)\n",
            "epoch:  664 loss:  tensor(0.2326, grad_fn=<MseLossBackward0>)\n",
            "epoch:  665 loss:  tensor(0.2326, grad_fn=<MseLossBackward0>)\n",
            "epoch:  666 loss:  tensor(0.2326, grad_fn=<MseLossBackward0>)\n",
            "epoch:  667 loss:  tensor(0.2326, grad_fn=<MseLossBackward0>)\n",
            "epoch:  668 loss:  tensor(0.2325, grad_fn=<MseLossBackward0>)\n",
            "epoch:  669 loss:  tensor(0.2325, grad_fn=<MseLossBackward0>)\n",
            "epoch:  670 loss:  tensor(0.2325, grad_fn=<MseLossBackward0>)\n",
            "epoch:  671 loss:  tensor(0.2324, grad_fn=<MseLossBackward0>)\n",
            "epoch:  672 loss:  tensor(0.2324, grad_fn=<MseLossBackward0>)\n",
            "epoch:  673 loss:  tensor(0.2324, grad_fn=<MseLossBackward0>)\n",
            "epoch:  674 loss:  tensor(0.2324, grad_fn=<MseLossBackward0>)\n",
            "epoch:  675 loss:  tensor(0.2323, grad_fn=<MseLossBackward0>)\n",
            "epoch:  676 loss:  tensor(0.2323, grad_fn=<MseLossBackward0>)\n",
            "epoch:  677 loss:  tensor(0.2323, grad_fn=<MseLossBackward0>)\n",
            "epoch:  678 loss:  tensor(0.2323, grad_fn=<MseLossBackward0>)\n",
            "epoch:  679 loss:  tensor(0.2322, grad_fn=<MseLossBackward0>)\n",
            "epoch:  680 loss:  tensor(0.2322, grad_fn=<MseLossBackward0>)\n",
            "epoch:  681 loss:  tensor(0.2322, grad_fn=<MseLossBackward0>)\n",
            "epoch:  682 loss:  tensor(0.2322, grad_fn=<MseLossBackward0>)\n",
            "epoch:  683 loss:  tensor(0.2321, grad_fn=<MseLossBackward0>)\n",
            "epoch:  684 loss:  tensor(0.2321, grad_fn=<MseLossBackward0>)\n",
            "epoch:  685 loss:  tensor(0.2321, grad_fn=<MseLossBackward0>)\n",
            "epoch:  686 loss:  tensor(0.2320, grad_fn=<MseLossBackward0>)\n",
            "epoch:  687 loss:  tensor(0.2320, grad_fn=<MseLossBackward0>)\n",
            "epoch:  688 loss:  tensor(0.2320, grad_fn=<MseLossBackward0>)\n",
            "epoch:  689 loss:  tensor(0.2320, grad_fn=<MseLossBackward0>)\n",
            "epoch:  690 loss:  tensor(0.2319, grad_fn=<MseLossBackward0>)\n",
            "epoch:  691 loss:  tensor(0.2319, grad_fn=<MseLossBackward0>)\n",
            "epoch:  692 loss:  tensor(0.2319, grad_fn=<MseLossBackward0>)\n",
            "epoch:  693 loss:  tensor(0.2319, grad_fn=<MseLossBackward0>)\n",
            "epoch:  694 loss:  tensor(0.2318, grad_fn=<MseLossBackward0>)\n",
            "epoch:  695 loss:  tensor(0.2318, grad_fn=<MseLossBackward0>)\n",
            "epoch:  696 loss:  tensor(0.2318, grad_fn=<MseLossBackward0>)\n",
            "epoch:  697 loss:  tensor(0.2317, grad_fn=<MseLossBackward0>)\n",
            "epoch:  698 loss:  tensor(0.2317, grad_fn=<MseLossBackward0>)\n",
            "epoch:  699 loss:  tensor(0.2317, grad_fn=<MseLossBackward0>)\n",
            "epoch:  700 loss:  tensor(0.2317, grad_fn=<MseLossBackward0>)\n",
            "epoch:  701 loss:  tensor(0.2316, grad_fn=<MseLossBackward0>)\n",
            "epoch:  702 loss:  tensor(0.2316, grad_fn=<MseLossBackward0>)\n",
            "epoch:  703 loss:  tensor(0.2316, grad_fn=<MseLossBackward0>)\n",
            "epoch:  704 loss:  tensor(0.2316, grad_fn=<MseLossBackward0>)\n",
            "epoch:  705 loss:  tensor(0.2315, grad_fn=<MseLossBackward0>)\n",
            "epoch:  706 loss:  tensor(0.2315, grad_fn=<MseLossBackward0>)\n",
            "epoch:  707 loss:  tensor(0.2315, grad_fn=<MseLossBackward0>)\n",
            "epoch:  708 loss:  tensor(0.2315, grad_fn=<MseLossBackward0>)\n",
            "epoch:  709 loss:  tensor(0.2314, grad_fn=<MseLossBackward0>)\n",
            "epoch:  710 loss:  tensor(0.2314, grad_fn=<MseLossBackward0>)\n",
            "epoch:  711 loss:  tensor(0.2314, grad_fn=<MseLossBackward0>)\n",
            "epoch:  712 loss:  tensor(0.2313, grad_fn=<MseLossBackward0>)\n",
            "epoch:  713 loss:  tensor(0.2313, grad_fn=<MseLossBackward0>)\n",
            "epoch:  714 loss:  tensor(0.2313, grad_fn=<MseLossBackward0>)\n",
            "epoch:  715 loss:  tensor(0.2313, grad_fn=<MseLossBackward0>)\n",
            "epoch:  716 loss:  tensor(0.2312, grad_fn=<MseLossBackward0>)\n",
            "epoch:  717 loss:  tensor(0.2312, grad_fn=<MseLossBackward0>)\n",
            "epoch:  718 loss:  tensor(0.2312, grad_fn=<MseLossBackward0>)\n",
            "epoch:  719 loss:  tensor(0.2312, grad_fn=<MseLossBackward0>)\n",
            "epoch:  720 loss:  tensor(0.2311, grad_fn=<MseLossBackward0>)\n",
            "epoch:  721 loss:  tensor(0.2311, grad_fn=<MseLossBackward0>)\n",
            "epoch:  722 loss:  tensor(0.2311, grad_fn=<MseLossBackward0>)\n",
            "epoch:  723 loss:  tensor(0.2310, grad_fn=<MseLossBackward0>)\n",
            "epoch:  724 loss:  tensor(0.2310, grad_fn=<MseLossBackward0>)\n",
            "epoch:  725 loss:  tensor(0.2310, grad_fn=<MseLossBackward0>)\n",
            "epoch:  726 loss:  tensor(0.2310, grad_fn=<MseLossBackward0>)\n",
            "epoch:  727 loss:  tensor(0.2309, grad_fn=<MseLossBackward0>)\n",
            "epoch:  728 loss:  tensor(0.2309, grad_fn=<MseLossBackward0>)\n",
            "epoch:  729 loss:  tensor(0.2309, grad_fn=<MseLossBackward0>)\n",
            "epoch:  730 loss:  tensor(0.2308, grad_fn=<MseLossBackward0>)\n",
            "epoch:  731 loss:  tensor(0.2308, grad_fn=<MseLossBackward0>)\n",
            "epoch:  732 loss:  tensor(0.2308, grad_fn=<MseLossBackward0>)\n",
            "epoch:  733 loss:  tensor(0.2307, grad_fn=<MseLossBackward0>)\n",
            "epoch:  734 loss:  tensor(0.2307, grad_fn=<MseLossBackward0>)\n",
            "epoch:  735 loss:  tensor(0.2307, grad_fn=<MseLossBackward0>)\n",
            "epoch:  736 loss:  tensor(0.2307, grad_fn=<MseLossBackward0>)\n",
            "epoch:  737 loss:  tensor(0.2306, grad_fn=<MseLossBackward0>)\n",
            "epoch:  738 loss:  tensor(0.2306, grad_fn=<MseLossBackward0>)\n",
            "epoch:  739 loss:  tensor(0.2306, grad_fn=<MseLossBackward0>)\n",
            "epoch:  740 loss:  tensor(0.2305, grad_fn=<MseLossBackward0>)\n",
            "epoch:  741 loss:  tensor(0.2305, grad_fn=<MseLossBackward0>)\n",
            "epoch:  742 loss:  tensor(0.2305, grad_fn=<MseLossBackward0>)\n",
            "epoch:  743 loss:  tensor(0.2304, grad_fn=<MseLossBackward0>)\n",
            "epoch:  744 loss:  tensor(0.2304, grad_fn=<MseLossBackward0>)\n",
            "epoch:  745 loss:  tensor(0.2304, grad_fn=<MseLossBackward0>)\n",
            "epoch:  746 loss:  tensor(0.2304, grad_fn=<MseLossBackward0>)\n",
            "epoch:  747 loss:  tensor(0.2303, grad_fn=<MseLossBackward0>)\n",
            "epoch:  748 loss:  tensor(0.2303, grad_fn=<MseLossBackward0>)\n",
            "epoch:  749 loss:  tensor(0.2303, grad_fn=<MseLossBackward0>)\n",
            "epoch:  750 loss:  tensor(0.2302, grad_fn=<MseLossBackward0>)\n",
            "epoch:  751 loss:  tensor(0.2302, grad_fn=<MseLossBackward0>)\n",
            "epoch:  752 loss:  tensor(0.2302, grad_fn=<MseLossBackward0>)\n",
            "epoch:  753 loss:  tensor(0.2301, grad_fn=<MseLossBackward0>)\n",
            "epoch:  754 loss:  tensor(0.2301, grad_fn=<MseLossBackward0>)\n",
            "epoch:  755 loss:  tensor(0.2301, grad_fn=<MseLossBackward0>)\n",
            "epoch:  756 loss:  tensor(0.2301, grad_fn=<MseLossBackward0>)\n",
            "epoch:  757 loss:  tensor(0.2300, grad_fn=<MseLossBackward0>)\n",
            "epoch:  758 loss:  tensor(0.2300, grad_fn=<MseLossBackward0>)\n",
            "epoch:  759 loss:  tensor(0.2300, grad_fn=<MseLossBackward0>)\n",
            "epoch:  760 loss:  tensor(0.2299, grad_fn=<MseLossBackward0>)\n",
            "epoch:  761 loss:  tensor(0.2299, grad_fn=<MseLossBackward0>)\n",
            "epoch:  762 loss:  tensor(0.2299, grad_fn=<MseLossBackward0>)\n",
            "epoch:  763 loss:  tensor(0.2298, grad_fn=<MseLossBackward0>)\n",
            "epoch:  764 loss:  tensor(0.2298, grad_fn=<MseLossBackward0>)\n",
            "epoch:  765 loss:  tensor(0.2298, grad_fn=<MseLossBackward0>)\n",
            "epoch:  766 loss:  tensor(0.2298, grad_fn=<MseLossBackward0>)\n",
            "epoch:  767 loss:  tensor(0.2297, grad_fn=<MseLossBackward0>)\n",
            "epoch:  768 loss:  tensor(0.2297, grad_fn=<MseLossBackward0>)\n",
            "epoch:  769 loss:  tensor(0.2297, grad_fn=<MseLossBackward0>)\n",
            "epoch:  770 loss:  tensor(0.2296, grad_fn=<MseLossBackward0>)\n",
            "epoch:  771 loss:  tensor(0.2296, grad_fn=<MseLossBackward0>)\n",
            "epoch:  772 loss:  tensor(0.2296, grad_fn=<MseLossBackward0>)\n",
            "epoch:  773 loss:  tensor(0.2295, grad_fn=<MseLossBackward0>)\n",
            "epoch:  774 loss:  tensor(0.2295, grad_fn=<MseLossBackward0>)\n",
            "epoch:  775 loss:  tensor(0.2295, grad_fn=<MseLossBackward0>)\n",
            "epoch:  776 loss:  tensor(0.2294, grad_fn=<MseLossBackward0>)\n",
            "epoch:  777 loss:  tensor(0.2294, grad_fn=<MseLossBackward0>)\n",
            "epoch:  778 loss:  tensor(0.2294, grad_fn=<MseLossBackward0>)\n",
            "epoch:  779 loss:  tensor(0.2294, grad_fn=<MseLossBackward0>)\n",
            "epoch:  780 loss:  tensor(0.2293, grad_fn=<MseLossBackward0>)\n",
            "epoch:  781 loss:  tensor(0.2293, grad_fn=<MseLossBackward0>)\n",
            "epoch:  782 loss:  tensor(0.2293, grad_fn=<MseLossBackward0>)\n",
            "epoch:  783 loss:  tensor(0.2292, grad_fn=<MseLossBackward0>)\n",
            "epoch:  784 loss:  tensor(0.2292, grad_fn=<MseLossBackward0>)\n",
            "epoch:  785 loss:  tensor(0.2292, grad_fn=<MseLossBackward0>)\n",
            "epoch:  786 loss:  tensor(0.2291, grad_fn=<MseLossBackward0>)\n",
            "epoch:  787 loss:  tensor(0.2291, grad_fn=<MseLossBackward0>)\n",
            "epoch:  788 loss:  tensor(0.2291, grad_fn=<MseLossBackward0>)\n",
            "epoch:  789 loss:  tensor(0.2290, grad_fn=<MseLossBackward0>)\n",
            "epoch:  790 loss:  tensor(0.2290, grad_fn=<MseLossBackward0>)\n",
            "epoch:  791 loss:  tensor(0.2290, grad_fn=<MseLossBackward0>)\n",
            "epoch:  792 loss:  tensor(0.2289, grad_fn=<MseLossBackward0>)\n",
            "epoch:  793 loss:  tensor(0.2289, grad_fn=<MseLossBackward0>)\n",
            "epoch:  794 loss:  tensor(0.2289, grad_fn=<MseLossBackward0>)\n",
            "epoch:  795 loss:  tensor(0.2288, grad_fn=<MseLossBackward0>)\n",
            "epoch:  796 loss:  tensor(0.2288, grad_fn=<MseLossBackward0>)\n",
            "epoch:  797 loss:  tensor(0.2288, grad_fn=<MseLossBackward0>)\n",
            "epoch:  798 loss:  tensor(0.2288, grad_fn=<MseLossBackward0>)\n",
            "epoch:  799 loss:  tensor(0.2287, grad_fn=<MseLossBackward0>)\n",
            "epoch:  800 loss:  tensor(0.2287, grad_fn=<MseLossBackward0>)\n",
            "epoch:  801 loss:  tensor(0.2287, grad_fn=<MseLossBackward0>)\n",
            "epoch:  802 loss:  tensor(0.2286, grad_fn=<MseLossBackward0>)\n",
            "epoch:  803 loss:  tensor(0.2286, grad_fn=<MseLossBackward0>)\n",
            "epoch:  804 loss:  tensor(0.2286, grad_fn=<MseLossBackward0>)\n",
            "epoch:  805 loss:  tensor(0.2285, grad_fn=<MseLossBackward0>)\n",
            "epoch:  806 loss:  tensor(0.2285, grad_fn=<MseLossBackward0>)\n",
            "epoch:  807 loss:  tensor(0.2285, grad_fn=<MseLossBackward0>)\n",
            "epoch:  808 loss:  tensor(0.2284, grad_fn=<MseLossBackward0>)\n",
            "epoch:  809 loss:  tensor(0.2284, grad_fn=<MseLossBackward0>)\n",
            "epoch:  810 loss:  tensor(0.2284, grad_fn=<MseLossBackward0>)\n",
            "epoch:  811 loss:  tensor(0.2283, grad_fn=<MseLossBackward0>)\n",
            "epoch:  812 loss:  tensor(0.2283, grad_fn=<MseLossBackward0>)\n",
            "epoch:  813 loss:  tensor(0.2283, grad_fn=<MseLossBackward0>)\n",
            "epoch:  814 loss:  tensor(0.2282, grad_fn=<MseLossBackward0>)\n",
            "epoch:  815 loss:  tensor(0.2282, grad_fn=<MseLossBackward0>)\n",
            "epoch:  816 loss:  tensor(0.2282, grad_fn=<MseLossBackward0>)\n",
            "epoch:  817 loss:  tensor(0.2281, grad_fn=<MseLossBackward0>)\n",
            "epoch:  818 loss:  tensor(0.2281, grad_fn=<MseLossBackward0>)\n",
            "epoch:  819 loss:  tensor(0.2281, grad_fn=<MseLossBackward0>)\n",
            "epoch:  820 loss:  tensor(0.2280, grad_fn=<MseLossBackward0>)\n",
            "epoch:  821 loss:  tensor(0.2280, grad_fn=<MseLossBackward0>)\n",
            "epoch:  822 loss:  tensor(0.2280, grad_fn=<MseLossBackward0>)\n",
            "epoch:  823 loss:  tensor(0.2279, grad_fn=<MseLossBackward0>)\n",
            "epoch:  824 loss:  tensor(0.2279, grad_fn=<MseLossBackward0>)\n",
            "epoch:  825 loss:  tensor(0.2279, grad_fn=<MseLossBackward0>)\n",
            "epoch:  826 loss:  tensor(0.2278, grad_fn=<MseLossBackward0>)\n",
            "epoch:  827 loss:  tensor(0.2278, grad_fn=<MseLossBackward0>)\n",
            "epoch:  828 loss:  tensor(0.2278, grad_fn=<MseLossBackward0>)\n",
            "epoch:  829 loss:  tensor(0.2277, grad_fn=<MseLossBackward0>)\n",
            "epoch:  830 loss:  tensor(0.2277, grad_fn=<MseLossBackward0>)\n",
            "epoch:  831 loss:  tensor(0.2277, grad_fn=<MseLossBackward0>)\n",
            "epoch:  832 loss:  tensor(0.2276, grad_fn=<MseLossBackward0>)\n",
            "epoch:  833 loss:  tensor(0.2276, grad_fn=<MseLossBackward0>)\n",
            "epoch:  834 loss:  tensor(0.2276, grad_fn=<MseLossBackward0>)\n",
            "epoch:  835 loss:  tensor(0.2275, grad_fn=<MseLossBackward0>)\n",
            "epoch:  836 loss:  tensor(0.2275, grad_fn=<MseLossBackward0>)\n",
            "epoch:  837 loss:  tensor(0.2275, grad_fn=<MseLossBackward0>)\n",
            "epoch:  838 loss:  tensor(0.2274, grad_fn=<MseLossBackward0>)\n",
            "epoch:  839 loss:  tensor(0.2274, grad_fn=<MseLossBackward0>)\n",
            "epoch:  840 loss:  tensor(0.2274, grad_fn=<MseLossBackward0>)\n",
            "epoch:  841 loss:  tensor(0.2273, grad_fn=<MseLossBackward0>)\n",
            "epoch:  842 loss:  tensor(0.2273, grad_fn=<MseLossBackward0>)\n",
            "epoch:  843 loss:  tensor(0.2273, grad_fn=<MseLossBackward0>)\n",
            "epoch:  844 loss:  tensor(0.2272, grad_fn=<MseLossBackward0>)\n",
            "epoch:  845 loss:  tensor(0.2272, grad_fn=<MseLossBackward0>)\n",
            "epoch:  846 loss:  tensor(0.2272, grad_fn=<MseLossBackward0>)\n",
            "epoch:  847 loss:  tensor(0.2271, grad_fn=<MseLossBackward0>)\n",
            "epoch:  848 loss:  tensor(0.2271, grad_fn=<MseLossBackward0>)\n",
            "epoch:  849 loss:  tensor(0.2271, grad_fn=<MseLossBackward0>)\n",
            "epoch:  850 loss:  tensor(0.2270, grad_fn=<MseLossBackward0>)\n",
            "epoch:  851 loss:  tensor(0.2270, grad_fn=<MseLossBackward0>)\n",
            "epoch:  852 loss:  tensor(0.2270, grad_fn=<MseLossBackward0>)\n",
            "epoch:  853 loss:  tensor(0.2269, grad_fn=<MseLossBackward0>)\n",
            "epoch:  854 loss:  tensor(0.2269, grad_fn=<MseLossBackward0>)\n",
            "epoch:  855 loss:  tensor(0.2269, grad_fn=<MseLossBackward0>)\n",
            "epoch:  856 loss:  tensor(0.2268, grad_fn=<MseLossBackward0>)\n",
            "epoch:  857 loss:  tensor(0.2268, grad_fn=<MseLossBackward0>)\n",
            "epoch:  858 loss:  tensor(0.2268, grad_fn=<MseLossBackward0>)\n",
            "epoch:  859 loss:  tensor(0.2267, grad_fn=<MseLossBackward0>)\n",
            "epoch:  860 loss:  tensor(0.2267, grad_fn=<MseLossBackward0>)\n",
            "epoch:  861 loss:  tensor(0.2267, grad_fn=<MseLossBackward0>)\n",
            "epoch:  862 loss:  tensor(0.2266, grad_fn=<MseLossBackward0>)\n",
            "epoch:  863 loss:  tensor(0.2266, grad_fn=<MseLossBackward0>)\n",
            "epoch:  864 loss:  tensor(0.2266, grad_fn=<MseLossBackward0>)\n",
            "epoch:  865 loss:  tensor(0.2265, grad_fn=<MseLossBackward0>)\n",
            "epoch:  866 loss:  tensor(0.2265, grad_fn=<MseLossBackward0>)\n",
            "epoch:  867 loss:  tensor(0.2264, grad_fn=<MseLossBackward0>)\n",
            "epoch:  868 loss:  tensor(0.2264, grad_fn=<MseLossBackward0>)\n",
            "epoch:  869 loss:  tensor(0.2264, grad_fn=<MseLossBackward0>)\n",
            "epoch:  870 loss:  tensor(0.2263, grad_fn=<MseLossBackward0>)\n",
            "epoch:  871 loss:  tensor(0.2263, grad_fn=<MseLossBackward0>)\n",
            "epoch:  872 loss:  tensor(0.2263, grad_fn=<MseLossBackward0>)\n",
            "epoch:  873 loss:  tensor(0.2262, grad_fn=<MseLossBackward0>)\n",
            "epoch:  874 loss:  tensor(0.2262, grad_fn=<MseLossBackward0>)\n",
            "epoch:  875 loss:  tensor(0.2262, grad_fn=<MseLossBackward0>)\n",
            "epoch:  876 loss:  tensor(0.2261, grad_fn=<MseLossBackward0>)\n",
            "epoch:  877 loss:  tensor(0.2261, grad_fn=<MseLossBackward0>)\n",
            "epoch:  878 loss:  tensor(0.2261, grad_fn=<MseLossBackward0>)\n",
            "epoch:  879 loss:  tensor(0.2260, grad_fn=<MseLossBackward0>)\n",
            "epoch:  880 loss:  tensor(0.2260, grad_fn=<MseLossBackward0>)\n",
            "epoch:  881 loss:  tensor(0.2259, grad_fn=<MseLossBackward0>)\n",
            "epoch:  882 loss:  tensor(0.2259, grad_fn=<MseLossBackward0>)\n",
            "epoch:  883 loss:  tensor(0.2259, grad_fn=<MseLossBackward0>)\n",
            "epoch:  884 loss:  tensor(0.2258, grad_fn=<MseLossBackward0>)\n",
            "epoch:  885 loss:  tensor(0.2258, grad_fn=<MseLossBackward0>)\n",
            "epoch:  886 loss:  tensor(0.2258, grad_fn=<MseLossBackward0>)\n",
            "epoch:  887 loss:  tensor(0.2257, grad_fn=<MseLossBackward0>)\n",
            "epoch:  888 loss:  tensor(0.2257, grad_fn=<MseLossBackward0>)\n",
            "epoch:  889 loss:  tensor(0.2257, grad_fn=<MseLossBackward0>)\n",
            "epoch:  890 loss:  tensor(0.2256, grad_fn=<MseLossBackward0>)\n",
            "epoch:  891 loss:  tensor(0.2256, grad_fn=<MseLossBackward0>)\n",
            "epoch:  892 loss:  tensor(0.2256, grad_fn=<MseLossBackward0>)\n",
            "epoch:  893 loss:  tensor(0.2255, grad_fn=<MseLossBackward0>)\n",
            "epoch:  894 loss:  tensor(0.2255, grad_fn=<MseLossBackward0>)\n",
            "epoch:  895 loss:  tensor(0.2254, grad_fn=<MseLossBackward0>)\n",
            "epoch:  896 loss:  tensor(0.2254, grad_fn=<MseLossBackward0>)\n",
            "epoch:  897 loss:  tensor(0.2254, grad_fn=<MseLossBackward0>)\n",
            "epoch:  898 loss:  tensor(0.2253, grad_fn=<MseLossBackward0>)\n",
            "epoch:  899 loss:  tensor(0.2253, grad_fn=<MseLossBackward0>)\n",
            "epoch:  900 loss:  tensor(0.2253, grad_fn=<MseLossBackward0>)\n",
            "epoch:  901 loss:  tensor(0.2252, grad_fn=<MseLossBackward0>)\n",
            "epoch:  902 loss:  tensor(0.2252, grad_fn=<MseLossBackward0>)\n",
            "epoch:  903 loss:  tensor(0.2251, grad_fn=<MseLossBackward0>)\n",
            "epoch:  904 loss:  tensor(0.2251, grad_fn=<MseLossBackward0>)\n",
            "epoch:  905 loss:  tensor(0.2251, grad_fn=<MseLossBackward0>)\n",
            "epoch:  906 loss:  tensor(0.2250, grad_fn=<MseLossBackward0>)\n",
            "epoch:  907 loss:  tensor(0.2250, grad_fn=<MseLossBackward0>)\n",
            "epoch:  908 loss:  tensor(0.2250, grad_fn=<MseLossBackward0>)\n",
            "epoch:  909 loss:  tensor(0.2249, grad_fn=<MseLossBackward0>)\n",
            "epoch:  910 loss:  tensor(0.2249, grad_fn=<MseLossBackward0>)\n",
            "epoch:  911 loss:  tensor(0.2248, grad_fn=<MseLossBackward0>)\n",
            "epoch:  912 loss:  tensor(0.2248, grad_fn=<MseLossBackward0>)\n",
            "epoch:  913 loss:  tensor(0.2248, grad_fn=<MseLossBackward0>)\n",
            "epoch:  914 loss:  tensor(0.2247, grad_fn=<MseLossBackward0>)\n",
            "epoch:  915 loss:  tensor(0.2247, grad_fn=<MseLossBackward0>)\n",
            "epoch:  916 loss:  tensor(0.2247, grad_fn=<MseLossBackward0>)\n",
            "epoch:  917 loss:  tensor(0.2246, grad_fn=<MseLossBackward0>)\n",
            "epoch:  918 loss:  tensor(0.2246, grad_fn=<MseLossBackward0>)\n",
            "epoch:  919 loss:  tensor(0.2245, grad_fn=<MseLossBackward0>)\n",
            "epoch:  920 loss:  tensor(0.2245, grad_fn=<MseLossBackward0>)\n",
            "epoch:  921 loss:  tensor(0.2245, grad_fn=<MseLossBackward0>)\n",
            "epoch:  922 loss:  tensor(0.2244, grad_fn=<MseLossBackward0>)\n",
            "epoch:  923 loss:  tensor(0.2244, grad_fn=<MseLossBackward0>)\n",
            "epoch:  924 loss:  tensor(0.2243, grad_fn=<MseLossBackward0>)\n",
            "epoch:  925 loss:  tensor(0.2243, grad_fn=<MseLossBackward0>)\n",
            "epoch:  926 loss:  tensor(0.2243, grad_fn=<MseLossBackward0>)\n",
            "epoch:  927 loss:  tensor(0.2242, grad_fn=<MseLossBackward0>)\n",
            "epoch:  928 loss:  tensor(0.2242, grad_fn=<MseLossBackward0>)\n",
            "epoch:  929 loss:  tensor(0.2242, grad_fn=<MseLossBackward0>)\n",
            "epoch:  930 loss:  tensor(0.2241, grad_fn=<MseLossBackward0>)\n",
            "epoch:  931 loss:  tensor(0.2241, grad_fn=<MseLossBackward0>)\n",
            "epoch:  932 loss:  tensor(0.2240, grad_fn=<MseLossBackward0>)\n",
            "epoch:  933 loss:  tensor(0.2240, grad_fn=<MseLossBackward0>)\n",
            "epoch:  934 loss:  tensor(0.2240, grad_fn=<MseLossBackward0>)\n",
            "epoch:  935 loss:  tensor(0.2239, grad_fn=<MseLossBackward0>)\n",
            "epoch:  936 loss:  tensor(0.2239, grad_fn=<MseLossBackward0>)\n",
            "epoch:  937 loss:  tensor(0.2238, grad_fn=<MseLossBackward0>)\n",
            "epoch:  938 loss:  tensor(0.2238, grad_fn=<MseLossBackward0>)\n",
            "epoch:  939 loss:  tensor(0.2238, grad_fn=<MseLossBackward0>)\n",
            "epoch:  940 loss:  tensor(0.2237, grad_fn=<MseLossBackward0>)\n",
            "epoch:  941 loss:  tensor(0.2237, grad_fn=<MseLossBackward0>)\n",
            "epoch:  942 loss:  tensor(0.2236, grad_fn=<MseLossBackward0>)\n",
            "epoch:  943 loss:  tensor(0.2236, grad_fn=<MseLossBackward0>)\n",
            "epoch:  944 loss:  tensor(0.2236, grad_fn=<MseLossBackward0>)\n",
            "epoch:  945 loss:  tensor(0.2235, grad_fn=<MseLossBackward0>)\n",
            "epoch:  946 loss:  tensor(0.2235, grad_fn=<MseLossBackward0>)\n",
            "epoch:  947 loss:  tensor(0.2234, grad_fn=<MseLossBackward0>)\n",
            "epoch:  948 loss:  tensor(0.2234, grad_fn=<MseLossBackward0>)\n",
            "epoch:  949 loss:  tensor(0.2234, grad_fn=<MseLossBackward0>)\n",
            "epoch:  950 loss:  tensor(0.2233, grad_fn=<MseLossBackward0>)\n",
            "epoch:  951 loss:  tensor(0.2233, grad_fn=<MseLossBackward0>)\n",
            "epoch:  952 loss:  tensor(0.2232, grad_fn=<MseLossBackward0>)\n",
            "epoch:  953 loss:  tensor(0.2232, grad_fn=<MseLossBackward0>)\n",
            "epoch:  954 loss:  tensor(0.2232, grad_fn=<MseLossBackward0>)\n",
            "epoch:  955 loss:  tensor(0.2231, grad_fn=<MseLossBackward0>)\n",
            "epoch:  956 loss:  tensor(0.2231, grad_fn=<MseLossBackward0>)\n",
            "epoch:  957 loss:  tensor(0.2230, grad_fn=<MseLossBackward0>)\n",
            "epoch:  958 loss:  tensor(0.2230, grad_fn=<MseLossBackward0>)\n",
            "epoch:  959 loss:  tensor(0.2230, grad_fn=<MseLossBackward0>)\n",
            "epoch:  960 loss:  tensor(0.2229, grad_fn=<MseLossBackward0>)\n",
            "epoch:  961 loss:  tensor(0.2229, grad_fn=<MseLossBackward0>)\n",
            "epoch:  962 loss:  tensor(0.2228, grad_fn=<MseLossBackward0>)\n",
            "epoch:  963 loss:  tensor(0.2228, grad_fn=<MseLossBackward0>)\n",
            "epoch:  964 loss:  tensor(0.2227, grad_fn=<MseLossBackward0>)\n",
            "epoch:  965 loss:  tensor(0.2227, grad_fn=<MseLossBackward0>)\n",
            "epoch:  966 loss:  tensor(0.2227, grad_fn=<MseLossBackward0>)\n",
            "epoch:  967 loss:  tensor(0.2226, grad_fn=<MseLossBackward0>)\n",
            "epoch:  968 loss:  tensor(0.2226, grad_fn=<MseLossBackward0>)\n",
            "epoch:  969 loss:  tensor(0.2225, grad_fn=<MseLossBackward0>)\n",
            "epoch:  970 loss:  tensor(0.2225, grad_fn=<MseLossBackward0>)\n",
            "epoch:  971 loss:  tensor(0.2225, grad_fn=<MseLossBackward0>)\n",
            "epoch:  972 loss:  tensor(0.2224, grad_fn=<MseLossBackward0>)\n",
            "epoch:  973 loss:  tensor(0.2224, grad_fn=<MseLossBackward0>)\n",
            "epoch:  974 loss:  tensor(0.2223, grad_fn=<MseLossBackward0>)\n",
            "epoch:  975 loss:  tensor(0.2223, grad_fn=<MseLossBackward0>)\n",
            "epoch:  976 loss:  tensor(0.2222, grad_fn=<MseLossBackward0>)\n",
            "epoch:  977 loss:  tensor(0.2222, grad_fn=<MseLossBackward0>)\n",
            "epoch:  978 loss:  tensor(0.2222, grad_fn=<MseLossBackward0>)\n",
            "epoch:  979 loss:  tensor(0.2221, grad_fn=<MseLossBackward0>)\n",
            "epoch:  980 loss:  tensor(0.2221, grad_fn=<MseLossBackward0>)\n",
            "epoch:  981 loss:  tensor(0.2220, grad_fn=<MseLossBackward0>)\n",
            "epoch:  982 loss:  tensor(0.2220, grad_fn=<MseLossBackward0>)\n",
            "epoch:  983 loss:  tensor(0.2219, grad_fn=<MseLossBackward0>)\n",
            "epoch:  984 loss:  tensor(0.2219, grad_fn=<MseLossBackward0>)\n",
            "epoch:  985 loss:  tensor(0.2219, grad_fn=<MseLossBackward0>)\n",
            "epoch:  986 loss:  tensor(0.2218, grad_fn=<MseLossBackward0>)\n",
            "epoch:  987 loss:  tensor(0.2218, grad_fn=<MseLossBackward0>)\n",
            "epoch:  988 loss:  tensor(0.2217, grad_fn=<MseLossBackward0>)\n",
            "epoch:  989 loss:  tensor(0.2217, grad_fn=<MseLossBackward0>)\n",
            "epoch:  990 loss:  tensor(0.2216, grad_fn=<MseLossBackward0>)\n",
            "epoch:  991 loss:  tensor(0.2216, grad_fn=<MseLossBackward0>)\n",
            "epoch:  992 loss:  tensor(0.2216, grad_fn=<MseLossBackward0>)\n",
            "epoch:  993 loss:  tensor(0.2215, grad_fn=<MseLossBackward0>)\n",
            "epoch:  994 loss:  tensor(0.2215, grad_fn=<MseLossBackward0>)\n",
            "epoch:  995 loss:  tensor(0.2214, grad_fn=<MseLossBackward0>)\n",
            "epoch:  996 loss:  tensor(0.2214, grad_fn=<MseLossBackward0>)\n",
            "epoch:  997 loss:  tensor(0.2213, grad_fn=<MseLossBackward0>)\n",
            "epoch:  998 loss:  tensor(0.2213, grad_fn=<MseLossBackward0>)\n",
            "epoch:  999 loss:  tensor(0.2212, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ]
    }
  ]
}